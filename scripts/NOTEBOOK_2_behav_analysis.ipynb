{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import join\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import scipy\n",
    "import json\n",
    "import statsmodels.formula.api as smf\n",
    "from collections import defaultdict\n",
    "from scipy.stats import wilcoxon, ttest_rel\n",
    "\n",
    "from functions import utils\n",
    "from functions import plotting\n",
    "from functions import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load subjects #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Included or excluded.xlsx document:\n",
    "onedrive_path = utils._get_onedrive_path()\n",
    "\n",
    "working_path = os.path.dirname(os.getcwd())\n",
    "results_path = join(working_path, \"results\")\n",
    "behav_results_saving_path = join(results_path, \"behav_results\")\n",
    "if not os.path.isdir(behav_results_saving_path):\n",
    "    os.makedirs(behav_results_saving_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the json file containing the included and excluded subjects\n",
    "# Open and read the JSON file\n",
    "included_excluded_file = join(behav_results_saving_path, 'final_included_subjects.json')\n",
    "with open(included_excluded_file, 'r') as file:\n",
    "    included_subjects = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_colors = utils.create_color_palette(included_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_color_palette(subject_colors, behav_results_saving_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = io.load_behav_data(included_subjects, onedrive_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {\n",
    "    'DBS OFF': '#20a39e', \n",
    "    'DBS ON': '#ef5b5b', \n",
    "    'control': '#ffba49', \n",
    "    'preop': '#8E7DBE',\n",
    "    'Session 1': \"#206ea1\", \n",
    "    'Session 2': \"#5FA363\", \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_dict = {\n",
    "    'sub006 DBS ON': 1,\n",
    "    'sub006 DBS OFF': 2,\n",
    "    'sub008 DBS ON': 1,\n",
    "    'sub008 DBS OFF': 2,\n",
    "    'sub009 DBS ON': 1,\n",
    "    'sub009 DBS OFF': 2,\n",
    "    'sub011 DBS ON': 2,\n",
    "    'sub011 DBS OFF': 1,\n",
    "    'sub015 DBS ON': 2,\n",
    "    'sub015 DBS OFF': 1,\n",
    "    'sub017 DBS ON': 1,\n",
    "    'sub017 DBS OFF': 2,\n",
    "    'sub019 DBS ON': 1,\n",
    "    'sub019 DBS OFF': 2,\n",
    "    'sub021 DBS ON': 2,\n",
    "    'sub021 DBS OFF': 1,\n",
    "    'sub023 DBS ON': 2,\n",
    "    'sub023 DBS OFF': 1,\n",
    "    'sub025 DBS ON': 1,\n",
    "    'sub025 DBS OFF': 2,\n",
    "    'sub027 DBS ON': 2,\n",
    "    'sub027 DBS OFF': 1,\n",
    "    'sub028 DBS OFF': 1,\n",
    "    'sub028 DBS ON': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bis_score_dict = {\n",
    "    'sub006 DBS ON': 29,\n",
    "    'sub006 DBS OFF': 29,\n",
    "    'sub011 DBS ON': 36,\n",
    "    'sub011 DBS OFF': 36,\n",
    "    'sub015 DBS ON': 24,\n",
    "    'sub015 DBS OFF': 24,\n",
    "    'sub019 DBS ON': 27,\n",
    "    'sub019 DBS OFF': 27,\n",
    "    'sub023 DBS ON': 38,\n",
    "    'sub023 DBS OFF': 38,\n",
    "    'sub025 DBS ON': 31,\n",
    "    'sub025 DBS OFF': 31,\n",
    "    'sub027 DBS ON': 32,\n",
    "    'sub027 DBS OFF': 32\n",
    "}\n",
    "\n",
    "bdi_score_dict = {\n",
    "    'sub006 DBS ON': 6,\n",
    "    'sub006 DBS OFF': 6,\n",
    "    'sub011 DBS ON': 27,\n",
    "    'sub011 DBS OFF': 27,\n",
    "    'sub015 DBS ON': 12,\n",
    "    'sub015 DBS OFF': 12,\n",
    "    'sub019 DBS ON': 10,\n",
    "    'sub019 DBS OFF': 10,\n",
    "    'sub023 DBS ON': 12,\n",
    "    'sub023 DBS OFF': 12,\n",
    "    'sub025 DBS ON': 17,\n",
    "    'sub025 DBS OFF': 17,\n",
    "    'sub027 DBS ON': 14,\n",
    "    'sub027 DBS OFF': 14\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extract main statistics and values for each subject and compile in a  dictionnary #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = utils.extract_stats(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries\n",
    "stats_OFF = {}\n",
    "stats_ON = {}\n",
    "stats_CONTROL = {}\n",
    "stats_PREOP = {}\n",
    "\n",
    "# Loop through the original dictionary and filter into sub-dictionaries\n",
    "for key, value in stats.items():\n",
    "    if \"OFF\" in key:\n",
    "        stats_OFF[key] = value\n",
    "    elif \"ON\" in key:\n",
    "        stats_ON[key] = value\n",
    "    elif \"C\" in key:\n",
    "        stats_CONTROL[key] = value\n",
    "    elif \"preop\" in key:\n",
    "        stats_PREOP[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Plot reaction times in the same order as trials ##\n",
    "(these could help see slowing during the task/block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_color_dict = {'go_trial': \"#4877D5\",\n",
    "                    'stop_trial': \"#d3075c\",\n",
    "                    'go_continue_trial': \"#FB9D05\",\n",
    "                    'go_fast_trial': \"#28B628\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_values_OFF = utils.get_group_values_ecdf(stats_OFF)\n",
    "group_values_ON = utils.get_group_values_ecdf(stats_ON)\n",
    "group_values_CONTROL = utils.get_group_values_ecdf(stats_CONTROL)\n",
    "group_values_PREOP = utils.get_group_values_ecdf(stats_PREOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_cumulative_rt_distributions_group_average(group_values_OFF, 'DBS OFF', trial_color_dict, behav_results_saving_path)\n",
    "plotting.plot_cumulative_rt_distributions_group_average(group_values_ON, 'DBS ON', trial_color_dict, behav_results_saving_path)\n",
    "plotting.plot_cumulative_rt_distributions_group_average(group_values_CONTROL, 'CONTROL', trial_color_dict, behav_results_saving_path)\n",
    "plotting.plot_cumulative_rt_distributions_group_average(group_values_PREOP, 'PREOP', trial_color_dict, behav_results_saving_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial_name in ['gf', 'go', 'gc', 'gs']:\n",
    "    plotting.plot_cumulative_rt_distributions_across_groups(\n",
    "            group_values_OFF,\n",
    "            group_values_ON,\n",
    "            group_values_CONTROL,\n",
    "            group_values_PREOP,\n",
    "            trial_name,\n",
    "            color_dict,\n",
    "            behav_results_saving_path\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_cumulative_rt_distributions(stats, trial_color_dict, behav_results_saving_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_all_sessions_prep_cost_across_blocks(\n",
    "        included_subjects, stats, subject_colors, behav_results_saving_path, \n",
    "        save_as_pdf=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_prep_cost_per_cond = plotting.plot_prep_cost_per_block_per_DBS_group(\n",
    "    included_subjects, stats, subject_colors, behav_results_saving_path, \n",
    "    color_dict, with_average_plot = True, save_as_pdf=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_prep_cost_per_session = plotting.plot_prep_cost_per_block_per_session_order(\n",
    "    included_subjects, stats, subject_colors, session_dict, behav_results_saving_path, \n",
    "    color_dict, with_average_plot = True, save_as_pdf=False    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there really is a learning effect... Let's check how much time was between two sessions for each subject:\n",
    "sub006 : 3 days between ON and OFF\n",
    "sub011 : 4 days between OFF and ON\n",
    "sub015 : 1 day between OFF and ON\n",
    "sub019 : 9 days between ON and OFF\n",
    "sub023 : 7 days between OFF and ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.bar_plot_prep_cost_per_block_per_condition(\n",
    "    dict_prep_cost_per_cond, color_dict, behav_results_saving_path,\n",
    "    save_as_pdf = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.whisker_plot_prep_cost_per_block_per_condition(\n",
    "    dict_prep_cost_per_cond, color_dict, behav_results_saving_path,\n",
    "    save_as_pdf = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.whisker_plot_prep_cost_per_block_per_session(\n",
    "    dict_prep_cost_per_session, color_dict, behav_results_saving_path,\n",
    "    save_as_pdf = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session-Based Analysis: Whisker Plot with Statistical Comparisons\n",
    "\n",
    "This plot shows the same whisker plot analysis but differentiates DBS subjects by **session** rather than DBS condition:\n",
    "\n",
    "- **Control** (yellow): Healthy control subjects\n",
    "- **Preop** (purple): Preoperative subjects  \n",
    "- **Session 1** (blue): DBS subjects tested in session 1\n",
    "- **Session 2** (red): DBS subjects tested in session 2\n",
    "\n",
    "### Key Findings:\n",
    "- **Session 1** subjects show lower preparation costs initially, with gradual increases across blocks\n",
    "- **Session 2** subjects have consistently higher preparation costs across all blocks\n",
    "- **Control** subjects show the highest preparation costs, especially in later blocks\n",
    "- Statistical comparisons within each group reveal significant changes across blocks (shown by significance bars)\n",
    "\n",
    "This analysis helps identify whether session-related factors (e.g., learning effects, fatigue, medication timing) influence preparation costs more than the DBS stimulation itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in included_subjects:\n",
    "    trial_IDs = stats[sub]['trial IDs']\n",
    "    trial_RTs = stats[sub]['RTs (ms)']\n",
    "    # replace nans with 0\n",
    "    trial_RTs = [0 if np.isnan(rt) else rt for rt in trial_RTs]\n",
    "    blocks = stats[sub]['block number']\n",
    "    y = np.arange(len(trial_RTs))\n",
    "\n",
    "    # Create figure with subplots for marginal distributions\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Create a grid layout\n",
    "    gs = fig.add_gridspec(3, 3, width_ratios=[1, 4, 1], height_ratios=[1, 4, 1],\n",
    "                         hspace=0.1, wspace=0.1)\n",
    "    \n",
    "    # Main scatter plot (center)\n",
    "    ax_main = fig.add_subplot(gs[1, 1])\n",
    "    \n",
    "    # Distribution plots\n",
    "    #ax_top = fig.add_subplot(gs[0, 1], sharex=ax_main)     # Top distribution (trial number)\n",
    "    ax_right = fig.add_subplot(gs[1, 2], sharey=ax_main)   # Right distribution (RT)\n",
    "    \n",
    "    # Main scatter plot\n",
    "    for i in range(len(trial_IDs)):\n",
    "        ax_main.scatter(y[i], trial_RTs[i], c=trial_color_dict[trial_IDs[i]], s=15)\n",
    "    \n",
    "    ax_main.set_xlabel('Trial number')\n",
    "    ax_main.set_ylabel('RT (ms)')\n",
    "    ax_main.set_ylim(-50, 1400)\n",
    "    ax_main.set_title(f'Reaction times of {sub}')\n",
    "    \n",
    "    # Add vertical lines for block changes\n",
    "    block_change_indices = [i for i in range(1, len(blocks)) if blocks[i] != blocks[i-1]]\n",
    "    for index in block_change_indices:\n",
    "        ax_main.axvline(x=index, color='grey', linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # Top distribution - RT distribution by trial number (optional: density over time)\n",
    "    trial_types = ['go_trial', 'stop_trial', 'go_continue_trial', 'go_fast_trial']\n",
    "    \n",
    "    # # Create stacked histogram on top showing trial type distribution over time\n",
    "    # bins = np.linspace(0, len(trial_RTs), 20)\n",
    "    # bottom = np.zeros(len(bins)-1)\n",
    "    \n",
    "    # for trial_type in trial_types:\n",
    "    #     trial_indices = [i for i, t in enumerate(trial_IDs) if t == trial_type]\n",
    "    #     hist, _ = np.histogram(trial_indices, bins=bins)\n",
    "    #     ax_top.bar(bins[:-1], hist, width=bins[1]-bins[0], bottom=bottom, \n",
    "    #                color=trial_color_dict[trial_type], alpha=0.7, \n",
    "    #                label=trial_type.replace('_', ' ').title())\n",
    "    #     bottom += hist\n",
    "    \n",
    "    # ax_top.set_ylabel('Trial Count')\n",
    "    # ax_top.tick_params(labelbottom=False)\n",
    "    \n",
    "    # Right distribution - RT distribution for each trial type\n",
    "    for i, trial_type in enumerate(trial_types):\n",
    "        trial_rts = [trial_RTs[j] for j in range(len(trial_IDs)) \n",
    "                    if trial_IDs[j] == trial_type and trial_RTs[j] > 0]\n",
    "        \n",
    "        if len(trial_rts) > 0:\n",
    "            # Create smooth distribution curve using seaborn's kdeplot\n",
    "            import seaborn as sns\n",
    "            \n",
    "            # Create a temporary dataframe for seaborn\n",
    "            temp_df = pd.DataFrame({'RT': trial_rts})\n",
    "            \n",
    "            # Plot horizontal KDE (kernel density estimation)\n",
    "            sns.kdeplot(data=temp_df, y='RT', ax=ax_right, \n",
    "                    color=trial_color_dict[trial_type], \n",
    "                    alpha=0.7, linewidth=2,\n",
    "                    label=trial_type.replace('_', ' ').title())\n",
    "\n",
    "    ax_right.set_xlabel('Density')\n",
    "    ax_right.tick_params(labelleft=False)\n",
    "    #ax_right.legend(loc='upper right')\n",
    "    \n",
    "    # Create legend\n",
    "    legend_handles = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                                label=trial_type.replace('_', ' ').title(), \n",
    "                                markerfacecolor=trial_color_dict[trial_type], \n",
    "                                markersize=10) for trial_type in trial_types]\n",
    "    \n",
    "    fig.legend(handles=legend_handles, loc='upper right', bbox_to_anchor=(0.95, 0.95))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_minus_GO_all = []\n",
    "SSRT_all = []\n",
    "# Calculate GC_minus_GO and SSRT for each subject\n",
    "for sub in included_subjects:\n",
    "    GC_minus_GO = stats[sub]['go_continue_trial mean RT (ms)'] - stats[sub]['go_trial mean RT (ms)']\n",
    "    SSRT = stats[sub]['SSRT (ms)']\n",
    "    GC_minus_GO_all.append(GC_minus_GO)\n",
    "    SSRT_all.append(SSRT)\n",
    "\n",
    "print(GC_minus_GO_all)\n",
    "print(SSRT_all)\n",
    "plt.scatter(SSRT_all, GC_minus_GO_all, color='black')\n",
    "plt.xlabel('SSRT (ms)')\n",
    "plt.ylabel('GC - GO RT (ms)')\n",
    "\n",
    "# perform person correlation\n",
    "corr, p_value = scipy.stats.pearsonr(SSRT_all, GC_minus_GO_all)\n",
    "print(f'Pearson correlation: {corr}, p-value: {p_value}')\n",
    "\n",
    "# plot the correlation line\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(SSRT_all, GC_minus_GO_all)\n",
    "x = np.array(SSRT_all)\n",
    "y = slope * x + intercept\n",
    "plt.plot(x, y, color='red', label='Fit line')\n",
    "plt.title(f'Correlation: r={corr:.2f}, p={p_value:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Plot the inhibition functions #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. For each subject and condition separately : to get a first impression of stopping difficulty and effect of DBS per subject ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = utils.create_grouped_df_for_inhibitory_functions(\n",
    "    included_subjects,\n",
    "    stats\n",
    ")\n",
    "\n",
    "plotting.plot_inhibitory_function_per_subject(grouped_df, color_dict, behav_results_saving_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Using the ZRFT method (Z-score) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_inhibitory_function_per_subject_zscored(\n",
    "    grouped_df,\n",
    "    stats,\n",
    "    color_dict,\n",
    "    behav_results_saving_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. All groups plotted using the ZRFT method to compare across groups ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_inhibitory_functions_per_groups(\n",
    "        grouped_df,\n",
    "        stats,\n",
    "        color_dict,\n",
    "        behav_results_saving_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Looking at reaction times on unsuccessful stop trials depending on SSD #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_inhibition_df = utils.create_inhibition_df(\n",
    "    included_subjects,\n",
    "    stats\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_reaction_time_relative_to_SSD(\n",
    "        rt_inhibition_df,\n",
    "        color_dict,\n",
    "        behav_results_saving_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Proactive inhibition #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Test if proactive inhibition is induced in all participants by comparing the reaction times for GO trials and GF trials ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.a. At the single subject and single session level ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_go_gf_rt_single_sub(stats_OFF,\n",
    "        stats_ON,\n",
    "        stats_CONTROL,\n",
    "        stats_PREOP,\n",
    "        color_dict,\n",
    "        behav_results_saving_path\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.b. At the group level (just out of interest) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_go_gf_rt_group(\n",
    "    stats_OFF,\n",
    "    stats_ON,\n",
    "    stats_CONTROL,\n",
    "    stats_PREOP,\n",
    "    color_dict,\n",
    "    behav_results_saving_path,\n",
    "    show_fig = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Assess proactive inhibition in included subjects ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1. Assess the effect of STN-DBS on proactive inhibition ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reshaped = plotting.plot_prep_cost_on_vs_off_only_sub_with_2_sessions(\n",
    "        stats_OFF,\n",
    "        stats_ON,\n",
    "        subject_colors,\n",
    "        behav_results_saving_path,\n",
    "        show_fig = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_prep_cost_on_vs_off_all_sub(\n",
    "        stats_OFF,\n",
    "        stats_ON,\n",
    "        subject_colors,\n",
    "        behav_results_saving_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2. Assess if the value in DBS OFF can predict the change with DBS ON ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reshaped_cleaned = df_reshaped.dropna()\n",
    "pre_treatment = df_reshaped_cleaned[\"DBS OFF\"].values\n",
    "post_treatment = df_reshaped_cleaned[\"DBS ON\"].values\n",
    "\n",
    "# Compute the change\n",
    "change = post_treatment - pre_treatment\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Pre_treatment': pre_treatment, 'Change': change})\n",
    "\n",
    "# Add a constant term for the intercept\n",
    "X = sm.add_constant(df['Pre_treatment'])  # Predictor (Pre-treatment values)\n",
    "y = df['Change']  # Dependent variable (Change)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print summary\n",
    "print(model.summary())\n",
    "\n",
    "# Scatter plot\n",
    "plt.scatter(df['Pre_treatment'], df['Change'], label=\"Data\")\n",
    "\n",
    "# Plot regression line\n",
    "x_vals = np.linspace(min(df['Pre_treatment']), max(df['Pre_treatment']), 100)\n",
    "y_vals = model.params[0] + model.params[1] * x_vals\n",
    "plt.plot(x_vals, y_vals, color='red', label=\"Regression Line\")\n",
    "\n",
    "plt.axhline(0, linestyle='--', color='gray')  # Reference line at y=0\n",
    "plt.xlabel(\"Pre-treatment Value\")\n",
    "plt.ylabel(\"Change (Post - Pre)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3. Compare all conditions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proactive_all = plotting.plot_prep_cost_all_groups(\n",
    "    stats_OFF,\n",
    "    stats_ON,\n",
    "    stats_CONTROL,\n",
    "    stats_PREOP,\n",
    "    color_dict,\n",
    "    behav_results_saving_path,\n",
    "    show_fig = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Reactive inhibition #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_SSRT_on_vs_off_all_sub(\n",
    "        stats_OFF,\n",
    "        stats_ON,\n",
    "        subject_colors,\n",
    "        behav_results_saving_path,\n",
    "        show_fig= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactive_all = plotting.plot_SSRT_all_groups(\n",
    "    stats_OFF,\n",
    "    stats_ON,\n",
    "    stats_CONTROL,\n",
    "    stats_PREOP,\n",
    "    color_dict,\n",
    "    behav_results_saving_path,\n",
    "    show_fig = True        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proactive_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactive_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Correlation proactive / reactive inhibition ? #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = utils.prepare_merged_dataframe(\n",
    "    df_proactive_all,\n",
    "    df_reactive_all,\n",
    "    stats_OFF,\n",
    "    stats_ON,\n",
    "    stats_CONTROL,\n",
    "    stats_PREOP,\n",
    "    behav_results_saving_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy df_merged but keep only subjects starting with \"sub\":\n",
    "df_merged_subs = df_merged[df_merged['Subject'].str.startswith('sub')].copy()\n",
    "df_merged_subs\n",
    "\n",
    "# Add a new column 'Session' using a session_dict  :\n",
    "df_merged_subs['Session'] = df_merged_subs['Subject'].map(session_dict)\n",
    "\n",
    "df_merged_subs['BIS'] = df_merged_subs['Subject'].map(bis_score_dict)\n",
    "\n",
    "df_merged_subs['BDI'] = df_merged_subs['Subject'].map(bdi_score_dict)\n",
    "\n",
    "# Add a new column 'DBS' to df_merged_subs based on the 'Subject' column:\n",
    "df_merged_subs['DBS'] = df_merged_subs['Subject'].apply(\n",
    "    lambda x: 'ON' if 'ON' in x else 'OFF')\n",
    "\n",
    "# in the Subject column, only keep th efirst part of the string before the space:\n",
    "df_merged_subs['Subject'] = df_merged_subs['Subject'].apply(lambda x: x.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: center the scores\n",
    "df_merged_subs['BIS_c'] = df_merged_subs['BIS'] - df_merged_subs['BIS'].mean()\n",
    "df_merged_subs['BDI_c'] = df_merged_subs['BDI'] - df_merged_subs['BDI'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.mixedlm(\n",
    "    formula=\"Q('SSRT (ms)') ~ DBS * BIS_c\",\n",
    "    data=df_merged_subs,\n",
    "    groups=\"Subject\"\n",
    ")\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_on = df_merged_subs[df_merged_subs['DBS'] == 'OFF']\n",
    "\n",
    "model_on = smf.mixedlm(\n",
    "    \"Q('preparation cost (ms)') ~ BDI_c\",  # only BDI score as fixed effect\n",
    "    data=df_on,\n",
    "    groups=\"Subject\"            # random intercept per subject\n",
    ")\n",
    "result_on = model_on.fit()\n",
    "print(result_on.summary())\n",
    "\n",
    "# Extract variables\n",
    "x = df_on['BDI']\n",
    "y = df_on['preparation cost (ms)']\n",
    "\n",
    "# Calculate Pearson correlation\n",
    "r, p_val = scipy.stats.pearsonr(x, y)\n",
    "\n",
    "# Fit linear regression manually to get slope and intercept\n",
    "slope, intercept = np.polyfit(x, y, 1)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.regplot(x=x, y=y, ci=None, scatter_kws={'s': 60, 'color': 'black'}, line_kws={'color': 'red'})\n",
    "\n",
    "# Set title with r and regression equation\n",
    "plt.title(f'Preparation cost vs BDI (DBS OFF)\\n'\n",
    "          f'r = {r:.2f}, p = {p_val:.3f}')\n",
    "\n",
    "plt.xlabel('BDI Score')\n",
    "plt.ylabel('Preparation score in DBS OFF (ms)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_on = df_merged_subs[df_merged_subs['DBS'] == 'ON']\n",
    "\n",
    "model_on = smf.mixedlm(\n",
    "    \"Q('SSRT (ms)') ~ BIS_c\",  # only BIS score as fixed effect\n",
    "    data=df_on,\n",
    "    groups=\"Subject\"            # random intercept per subject\n",
    ")\n",
    "result_on = model_on.fit()\n",
    "print(result_on.summary())\n",
    "\n",
    "# Extract variables\n",
    "x = df_on['BIS']\n",
    "y = df_on['SSRT (ms)']\n",
    "\n",
    "# Calculate Pearson correlation\n",
    "r, p_val = scipy.stats.pearsonr(x, y)\n",
    "\n",
    "# Fit linear regression manually to get slope and intercept\n",
    "slope, intercept = np.polyfit(x, y, 1)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.regplot(x=x, y=y, ci=None, scatter_kws={'s': 60, 'color': 'black'}, line_kws={'color': 'red'})\n",
    "\n",
    "# Set title with r and regression equation\n",
    "plt.title(f'SSRT vs BIS (DBS ON)\\n'\n",
    "          f'r = {r:.2f}, p = {p_val:.3f}')\n",
    "\n",
    "plt.xlabel('BIS Score')\n",
    "plt.ylabel('SSRT in DBS ON (ms)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure DBS and Session are treated as categorical variables\n",
    "df_merged_subs['DBS'] = df_merged_subs['DBS'].astype('category')\n",
    "df_merged_subs['Session'] = df_merged_subs['Session'].astype('category')\n",
    "\n",
    "# Fit the model\n",
    "model = smf.mixedlm(\n",
    "    formula=\"Q('preparation cost (ms)') ~ DBS + Session\",  # fixed effects\n",
    "    data=df_merged_subs,\n",
    "    groups=\"Subject\"  # random intercept per subject\n",
    ")\n",
    "result = model.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term\t        Coef.   \tp-value \tInterpretation\n",
    "\n",
    "Intercept\t    45.60\t    0.121\t    Baseline prep cost (DBS=OFF, Session=1) — not significantly different from 0.\n",
    "\n",
    "DBS[T.ON]\t    4.17\t    0.797\t    DBS ON increases prep cost by ~4.2 ms vs OFF — not significant.\n",
    "\n",
    "Session[T.2]\t51.74   \t0.001\t    Session 2 increases prep cost by ~52 ms vs Session 1 — statistically significant.\n",
    "\n",
    "\n",
    "✅ Only Session has a significant effect on the preparation cost.\n",
    "\n",
    "Preparation cost is higher in the second session, regardless of DBS status.\n",
    "\n",
    "DBS has a negligible and non-significant effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model = smf.mixedlm(\n",
    "    formula=\"Q('SSRT (ms)') ~ DBS + Session\",  # fixed effects\n",
    "    data=df_merged_subs,\n",
    "    groups=\"Subject\"  # random intercept per subject\n",
    ")\n",
    "result = model.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT: We fitted a linear mixed model with SSRT as the dependent variable, DBS and Session as fixed effects, and Subject as a random effect. Neither DBS (p = 0.66) nor Session (p = 0.69) significantly affected SSRT. However, subject-level variance was high, suggesting large individual differences in SSRT performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model = smf.mixedlm(\n",
    "    formula=\"Q('mean SSD (ms)') ~ DBS + Session\",  # fixed effects\n",
    "    data=df_merged_subs,\n",
    "    groups=\"Subject\"  # random intercept per subject\n",
    ")\n",
    "result = model.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_corr_prep_cost_SSRT(df_merged, behav_results_saving_path, show_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Correlation SSD and SSRT in reactive inhibition? #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_corr_SSD_SSRT(df_merged, behav_results_saving_path, show_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Effect of STN-DBS on Success Rate #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_dbs_effect_success_rate_single_sub(\n",
    "        stats_OFF,\n",
    "        stats_ON,\n",
    "        behav_results_saving_path,\n",
    "        show_fig=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_type = ['GO', 'GC', 'GF', 'Go-STOP']\n",
    "for trial in trial_type:\n",
    "    plotting.plot_percent_success_on_vs_off(\n",
    "            stats_OFF=stats_OFF,\n",
    "            stats_ON=stats_ON,\n",
    "            trial_type=trial,\n",
    "            subject_colors=subject_colors,\n",
    "            behav_results_saving_path=behav_results_saving_path,\n",
    "                show_fig=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dbs = {}\n",
    "subject_ids = [key.split(' ')[0] for key in stats_OFF.keys() if 'OFF' in key]\n",
    "\n",
    "for sub in subject_ids: \n",
    "    stats_dbs[sub] = {\n",
    "        'OFF': stats_OFF[f'{sub} DBS OFF mSST'],\n",
    "        'ON': stats_ON[f'{sub} DBS ON mSST'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data in a long format suitable for seaborn's violin plot\n",
    "plot_data = []\n",
    "\n",
    "# Define trial types and bar width\n",
    "trial_types = ['go_trial', 'stop_trial', 'go_fast_trial', 'go_continue_trial']\n",
    "bar_width = 0.3\n",
    "index = np.arange(len(trial_types))\n",
    "opacity = 0.8\n",
    "\n",
    "# Create an empty dataframe to store success rates for each participant\n",
    "columns = ['subject_id', 'trial_type', 'off_percent', 'on_percent']\n",
    "success_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Access data for a single subject in OFF and ON conditions\n",
    "for subject_id in stats_dbs.keys():\n",
    "    stats_dbs_new = {\n",
    "        'OFF': stats_dbs[subject_id]['OFF'],\n",
    "        'ON': stats_dbs[subject_id]['ON']\n",
    "    }\n",
    "    print(stats_dbs_new)\n",
    "\n",
    "    # Retrieve values for each trial type in both conditions\n",
    "    off_values = [\n",
    "        stats_dbs_new['OFF']['percent correct go_trial'],\n",
    "        stats_dbs_new['OFF']['percent correct stop_trial'],\n",
    "        stats_dbs_new['OFF']['percent correct go_fast_trial'],\n",
    "        stats_dbs_new['OFF']['percent correct go_continue_trial']\n",
    "    ]\n",
    "\n",
    "    on_values = [\n",
    "        stats_dbs_new['ON']['percent correct go_trial'],\n",
    "        stats_dbs_new['ON']['percent correct stop_trial'],\n",
    "        stats_dbs_new['ON']['percent correct go_fast_trial'],\n",
    "        stats_dbs_new['ON']['percent correct go_continue_trial']\n",
    "    ]\n",
    "\n",
    "    # Add the subject data to the dataframe\n",
    "    for i, trial_type in enumerate(trial_types):\n",
    "        success_df = success_df.append({\n",
    "            'subject_id': subject_id,\n",
    "            'trial_type': trial_type,\n",
    "            'off_percent': off_values[i],\n",
    "            'on_percent': on_values[i]\n",
    "        }, ignore_index=True)\n",
    "\n",
    "for trial_type in trial_types:\n",
    "    trial_data = success_df[success_df['trial_type'] == trial_type]\n",
    "\n",
    "    # Add data for OFF and ON conditions in the long format\n",
    "    trial_data_off = trial_data[['subject_id', 'off_percent']].rename(columns={'off_percent': 'percent_correct'})\n",
    "    trial_data_off['condition'] = 'OFF'\n",
    "    \n",
    "    trial_data_on = trial_data[['subject_id', 'on_percent']].rename(columns={'on_percent': 'percent_correct'})\n",
    "    trial_data_on['condition'] = 'ON'\n",
    "    \n",
    "    # Combine both conditions into one DataFrame\n",
    "    trial_data_combined = pd.concat([trial_data_off, trial_data_on])\n",
    "\n",
    "    # Add trial type information for plotting\n",
    "    trial_data_combined['trial_type'] = trial_type\n",
    "    \n",
    "    plot_data.append(trial_data_combined)\n",
    "\n",
    "# Combine all trial data into one dataframe\n",
    "plot_data = pd.concat(plot_data)\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create a violin plot for each trial type\n",
    "sns.violinplot(x='trial_type', y='percent_correct', hue='condition', data=plot_data, split=True, \n",
    "               palette={'OFF': '#20a39e', 'ON': '#ef5b5b'}, alpha = 0.2, inner='quart', linewidth=1.25)\n",
    "\n",
    "# Initialize lists for legend handles and labels\n",
    "handles = []\n",
    "labels = []\n",
    "\n",
    "# Add colored dots for each participant\n",
    "for i, trial_type in enumerate(trial_types):\n",
    "    trial_data_for_dots = plot_data[plot_data['trial_type'] == trial_type]\n",
    "    \n",
    "    # Create a color map for each participant\n",
    "    subject_colors = {subject: sns.color_palette(\"deep\", len(trial_data_for_dots['subject_id'].unique()))[i] \n",
    "                      for i, subject in enumerate(trial_data_for_dots['subject_id'].unique())}\n",
    "\n",
    "    for subject_id, color in subject_colors.items():\n",
    "        subject_data = trial_data_for_dots[trial_data_for_dots['subject_id'] == subject_id]\n",
    "        \n",
    "        # Extract OFF and ON data points\n",
    "        off_value = subject_data[subject_data['condition'] == 'OFF']['percent_correct'].values\n",
    "        on_value = subject_data[subject_data['condition'] == 'ON']['percent_correct'].values\n",
    "        \n",
    "        # Offset x positions for visual clarity\n",
    "        j = np.random.uniform(-0.1, 0.1)  # Random offset for each subject\n",
    "        x_pos = [i - 0.15 + j, i + 0.15 + j]\n",
    "        \n",
    "        # Scatter plot for each participant's result\n",
    "        scatter = plt.scatter(x_pos, [off_value, on_value], color=color, edgecolors='black', s=100)\n",
    "        \n",
    "        # **NEW: Add line connecting OFF and ON dots for each subject**\n",
    "        plt.plot(x_pos, [off_value, on_value], color=color, alpha=0.7, linestyle='-', linewidth=1)\n",
    "\n",
    "        # Add to the legend (only add each subject once)\n",
    "        if subject_id not in labels:\n",
    "            handles.append(scatter)\n",
    "            labels.append(subject_id)\n",
    "\n",
    "# Add t-test results to each subplot\n",
    "for i, trial_type in enumerate(trial_types):\n",
    "    trial_data_for_ttest = plot_data[plot_data['trial_type'] == trial_type]\n",
    "    # t_stat, p_value = scipy.stats.ttest_rel(\n",
    "    #     trial_data_for_ttest[trial_data_for_ttest['condition'] == 'OFF']['percent_correct'],\n",
    "    #     trial_data_for_ttest[trial_data_for_ttest[ 'condition'] == 'ON']['percent_correct']\n",
    "    # )\n",
    "    test_result, p_value = scipy.stats.wilcoxon(\n",
    "        trial_data_for_ttest[trial_data_for_ttest['condition'] == 'OFF']['percent_correct'],\n",
    "        trial_data_for_ttest[trial_data_for_ttest[ 'condition'] == 'ON']['percent_correct']\n",
    "        )\n",
    "    \n",
    "    plt.text(i, 105, f\"statistic = {test_result:.3f}\\npval = {p_value:.3f}\", \n",
    "             horizontalalignment='center', fontsize=12, verticalalignment='bottom')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Trial Type', fontsize=14)\n",
    "plt.ylabel('Percent Correct', fontsize=14)\n",
    "plt.title('Comparison of Performance Between OFF and ON Conditions', fontsize=16)\n",
    "\n",
    "# Custom legend for OFF and ON condition colors\n",
    "from matplotlib.patches import Patch\n",
    "condition_legend_handles = [\n",
    "    Patch(color='#20a39e', label='OFF'),\n",
    "    Patch(color='#ef5b5b', label='ON')\n",
    "]\n",
    "\n",
    "# Create two legends: one for OFF/ON conditions, one for subjects\n",
    "legend1 = plt.legend(handles=condition_legend_handles, title=\"Condition\", loc='upper right', fontsize=12)\n",
    "plt.gca().add_artist(legend1)  # Ensure the first legend stays\n",
    "\n",
    "# Second legend for subject IDs\n",
    "plt.legend(handles=handles, labels=labels, title=\"Subject ID\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Effect of DBS on Reaction Time #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_type = ['GO', 'GC', 'GF', 'Go-STOP']\n",
    "for trial in trial_type:\n",
    "    plotting.plot_reaction_time_on_vs_off(\n",
    "            stats_OFF=stats_OFF,\n",
    "            stats_ON=stats_ON,\n",
    "            trial_type=trial,\n",
    "            subject_colors=subject_colors,\n",
    "            behav_results_saving_path=behav_results_saving_path,\n",
    "        show_fig=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_dbs_effect_reaction_time_single_sub(\n",
    "        stats_OFF,\n",
    "        stats_ON,\n",
    "        behav_results_saving_path,\n",
    "        show_fig=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_dbs_effect_on_rt_all_sub_with_2_sessions_all_trial_types(\n",
    "        stats_OFF,\n",
    "        stats_ON,\n",
    "        subject_colors,\n",
    "        behav_results_saving_path,\n",
    "        show_fig=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Test if RT during GO trials correlates with SSRT # (should not!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_corr_gort_ssrt(\n",
    "    stats,    \n",
    "    behav_results_saving_path,\n",
    "    show_fig=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_early_press_on_vs_off(\n",
    "        stats_OFF,\n",
    "        stats_ON,\n",
    "        subject_colors,\n",
    "        behav_results_saving_path,\n",
    "        show_fig=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "excel_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
