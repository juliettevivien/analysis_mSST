{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f4d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT EXTERNAL FUNCTIONS\n",
    "import mne\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.preprocessing import ICA, read_ica\n",
    "from mne_icalabel import label_components\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "\n",
    "os.getcwd()\n",
    "import functions.io as io\n",
    "import functions.utils as utils\n",
    "import functions.preprocessing as preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c39c618",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "- Loads data (single sub)\n",
    "- Checks unit of raw data (without any manipulation of raw, just checking)\n",
    "- Dropping channels that aren't of interest, and setting channel types (you will want to keep X.Y,Z channels though!)\n",
    "- Re-scales data and replaces raw (if check above suggests that data is in \"raw units ADC\" from amplifier. If one needs to be rescaled all do, but I keep the check in here just so I/we know what's going on and why we're rescaling)\n",
    "- Set montage (so that each electrode has it's location when we use scalp tophographies for visualisations and electrode placement (and later for other stuff I assume))\n",
    "- High- and low-pass filter + notch filter\n",
    "- Annotate breaks, so that beginning, breaks between blocks, and end isn't included in the analyses. I found that if we crop the event timings get shifted, if we just annotate here then we don't shift any times and events around, and the \"bad\" parts are not included in analyses.\n",
    "- Plot raw trace and manually annotate bad parts of raw trace (I think only the most obvious movements/artefacts with huge shifts amplitude). Annotating can be done when seeing raw traces interactivately, click \"a\" on keybord to get the \"helper/info\" and then type \"movement\" straight away and hit enter. This creates a new \"marker\" which you then use to mark bad segments (click and drag over the bad segments). Also remove obviously bad channels here (more info at that stage).\n",
    "- Following this, when the obviously bad movements/artefacts/channels are removed, we can run some checks on channels to check if they are likely to be bad or not - see more info at that point in the notebook. I still don't know what's \"appropriate\" to do here, but the code is there if useful, and if the results can be used to guide selection of channels?\n",
    "- After all removal -> re-reference to average\n",
    "- Run ICA and save it so I don't need to re-run it later (if everything is identical in preprocessing), but can load it and apply it to the data again with e.g., other components removed etc. \n",
    "- Plot ICA components to see topographies, time series of components, how much variance is explained by the components etc (I don't really understand this variance fully, what is good and what is bad? Is there a good and bad?). Then some mne functions that \"automatically\" suggests which components are likely to be ECG, EOG, and mostly muscle noise. I think for now i prefer to do it manually, and use these checks as guides and compare to what I think the components are - see more notes at that point in the notebook.\n",
    "- Select bad components and remove them \n",
    "- Apply the ICA to data\n",
    "- After this the preprocessing of raw data is done. \n",
    "\n",
    "\n",
    "I then have parts where I epoch the data, and then remove bad epochs (the parts I have previously marked as bad are still in the data, because when I load the epochs I tell it to also include what segments of the raw trace I marked as bad to be excluded. I found that if I exclude the \"bad_movement\" I marked manually before ICA, all my epoch indexes are shifted because parts of the data has been removed, so the behavioural file index and actual remaining data indexes are not matching and I'm pulling the wrong epochs in my extract epoch functions. By keeping the \"bad_movement\" data in when I extract epochs, no data is removed when epochs are created, so I will have to quickly go over and just remove those that are bad again). This could probably be done in a smoother way, but I don't find this too annyoing to do, at epoch level it doesn't take too long to quickly scan through. \n",
    "\n",
    "\n",
    "I plot (and save) PSDs regularly to see what the impact the different preprocessing steps have. Might not be necessary later on - but for now i find it ok. \n",
    "I also save the file after some steps (it is marked when saved), so that the steps that takes long/are tedious don't have to be re-done all the time if wanting to test different methods etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae28d814",
   "metadata": {},
   "source": [
    "# 1. Load dataset and prepare for pre-processing #\n",
    "\n",
    "1. Load one EEG raw dataset and its associated impedances files\n",
    "2. Change channel types to match recording setup & remove unnecessary channels (like TRIGGERS, STATUS, ETC.)\n",
    "3. Apply the 10-20 montage to EEG recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00371ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session to preprocess\n",
    "session_id = \"sub027 DBS OFF mSST\"\n",
    "\n",
    "working_path = os.path.dirname(os.getcwd())\n",
    "onedrive_path = utils._get_onedrive_path()\n",
    "\n",
    "sub = session_id.split(' ') [0]\n",
    "condition = session_id.split(' ') [1] + ' ' + session_id.split(' ') [2]\n",
    "sub_onedrive_path_task = join(onedrive_path, sub, 'synced_data', session_id)\n",
    "\n",
    "#  Set saving path\n",
    "results_path = join(working_path, \"results\")\n",
    "saving_path = join(results_path, session_id)\n",
    "if not os.path.isdir(saving_path):\n",
    "    os.makedirs(saving_path)\n",
    "sub_save_path = join(saving_path, \"figures\")\n",
    "os.makedirs(sub_save_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "save_path = os.path.join(saving_path,\"data\")\n",
    "os.makedirs(save_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# Load raw data\n",
    "filename = [f for f in os.listdir(sub_onedrive_path_task) if (\n",
    "    f.endswith('.set') and f.startswith('SYNCHRONIZED_EXTERNAL'))]\n",
    "file = join(sub_onedrive_path_task, filename[0])\n",
    "raw = mne.io.read_raw(file, preload=True)\n",
    "\n",
    "# also load the two impedance files to check channels briefly\n",
    "impedance_folder = join(onedrive_path, sub, 'raw_data', 'XDF', condition)\n",
    "impedance_begin_filename = [f for f in os.listdir(impedance_folder) if (\n",
    "    f.endswith('.txt') and f.startswith('mSST_impedances_begin'))]\n",
    "impedance_end_filename = [f for f in os.listdir(impedance_folder) if (\n",
    "    f.endswith('.txt') and f.startswith('mSST_impedances_end'))]\n",
    "file_begin = join(impedance_folder, impedance_begin_filename[0])\n",
    "file_end = join(impedance_folder, impedance_end_filename[0])\n",
    "impedance_begin = pd.read_csv(file_begin, sep='\\t', header=None)\n",
    "impedance_end = pd.read_csv(file_end, sep='\\t', header=None)\n",
    "impedance_begin.drop(2, axis=1, inplace=True)  \n",
    "impedance_end.drop(2, axis=1, inplace=True)\n",
    "imp = impedance_begin.merge(impedance_end, on=0, how='outer', suffixes=('_begin', '_end'))\n",
    "# remove all rows starting with 'UNI':\n",
    "imp = imp[~imp[0].str.startswith('UNI')]\n",
    "\n",
    "# flag channels with impedance above 25 kOhm:\n",
    "high_imp_channels = imp[(imp['1_begin'] > 25) | (imp['1_end'] > 25)]\n",
    "if not high_imp_channels.empty:\n",
    "    print(\"Channels with high impedance (> 25 kOhm):\")\n",
    "    print(high_imp_channels)\n",
    "else:\n",
    "    print(\"No channels with high impedance found.\")\n",
    "\n",
    "sf = raw.info['sfreq']\n",
    "print(f\"Sampling frequency: {sf} Hz\")\n",
    "\n",
    "raw.drop_channels(['CREF', 'X', 'Y', 'Z', 'TRIGGERS', 'STATUS', 'COUNTER', 'BIP 01'])\n",
    "raw.set_channel_types({'BIP 02': 'ecg', 'BIP 03': 'eog'}) \n",
    "\n",
    "# set 10-20 montage\n",
    "data = raw.set_montage('standard_1020', match_case=False, match_alias=True, on_missing='warn') \n",
    "ch_names = data.ch_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12473b7",
   "metadata": {},
   "source": [
    "#### Plot raw PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc91e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "### Plot PSD of signal (averaging all channels)\n",
    "psd_raw_avg = data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=0, fmax=130, n_fft=round(sf)*2, n_overlap=int(round(sf)), window=\"hamming\")\n",
    "psd_raw_avg.plot(dB=True, average=True).suptitle(f\"Raw PSD {sub}\")\n",
    "plt.show()\n",
    "\n",
    "### Plot PSD of signal (not averaging)\n",
    "psd_raw = data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=0, fmax=130, n_fft=round(sf)*2, n_overlap=int(round(sf)), window=\"hamming\")\n",
    "psd_raw.plot(dB=True, average=False).suptitle(f\"Raw PSD {sub}\")\n",
    "plt.savefig(join(sub_save_path, f\"{sub}_raw_PSD_avg.png\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a440b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "data.plot(duration = 20, n_channels = len(ch_names), scalings=\"auto\", title=\"Raw data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb3a2e9",
   "metadata": {},
   "source": [
    "# 2. Filter the data #\n",
    "\n",
    "1. Apply high-pass filter at 1Hz to remove slow-drifts\n",
    "2. Apply low-pass filter at 80Hz to remove DBS main artifact and only keep frequencies of interest for futher analysis\n",
    "3. Apply notch filter at 50Hz to remove line noise\n",
    "4. Additionnally if another artifactual peak is visible in the PSD (aliased stimulation frequency...), add another notch-filter around it to dampen it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752322ae",
   "metadata": {},
   "source": [
    "## 2.1. COMMON filtering steps: High- and low-pass filtering + notch ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd67658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first apply 1Hz high pass filter\n",
    "high_passed_filt_eeg_data = data.copy().filter(1, None) \n",
    "\n",
    "# then apply 80Hz low pass filter\n",
    "high_low_passed_filt_eeg_data = high_passed_filt_eeg_data.copy().filter(None, 80) \n",
    "\n",
    "# Last, apply notch filter(s)\n",
    "# Even if 50Hz activity is not present in the raw, it is sometimes present after re-referencing\n",
    "# Therefore, it is safer to apply a notch filter at 50Hz for all sessions.\n",
    "filt_eeg_data = high_low_passed_filt_eeg_data.copy().notch_filter(50) \n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "### Plot PSD of signal (averaging all channels)\n",
    "psd_filt_avg = filt_eeg_data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=0, fmax=100, n_fft=round(sf)*2, n_overlap=int(round(sf)), window=\"hamming\")\n",
    "psd_filt_avg.plot(dB=True, average=True).suptitle(f\"{sub} Filtered PSD\")\n",
    "plt.show()\n",
    "\n",
    "### Plot PSD of signal (not averaging)\n",
    "psd_filt = filt_eeg_data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=0, fmax=100, n_fft=round(sf)*2, n_overlap=int(round(sf)), window=\"hamming\")\n",
    "psd_filt.plot(dB=True, average=False).suptitle(f\"{sub} Filtered PSD\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce92c7f",
   "metadata": {},
   "source": [
    "## 2.2. SPECIFIC step: filter out potential other artifacts ##\n",
    "\n",
    "e.g. in our recordings at 2048Hz, we commonly see a peak at 48Hz coming from the aliasing of the 16th harmonic of 125Hz DBS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0428d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_eeg_data.notch_filter(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9db65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_eeg_data.notch_filter(77)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc4f227",
   "metadata": {},
   "source": [
    "# 3. Identify and interpolate bad channels before re-referencing to average reference #\n",
    "\n",
    "1. Get a first general idea of \"bad\" channels using automatic classification\n",
    "2. Plot data and scroll through the full recording session: check channels flagged in the automatic detection method, and if necessary delete other bad-looking channels \n",
    "3. Interpolate channels labeled as bad\n",
    "4. Re-reference to average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c207f4",
   "metadata": {},
   "source": [
    "## 3.1. Recognising bad channels by Z-scoring and looking at SD and variance in freq. and time domain ##\n",
    "\n",
    "**PSD_Z:**\n",
    "- Computes each channel’s average power (1–80 Hz) in dB, then z-scores across channels—so it flags electrodes whose overall spectral “bulk” is unusually high or low (e.g., a consistently noisy or dead contact) (A single value per channel, tells us whether the channel is generally noisier or quieter than the others) (looks at Frequency domain).\n",
    "\n",
    "**P2P_Z:**\n",
    "- Measures the maximum 250 ms peak-to-peak excursion per channel and z-scores those values—so it catches electrodes with extreme transients (cable pops, big spikes) or abnormally flat signals (looks at Time domain)\n",
    "(Takes the highest voltage the channel reaches minus the lowest voltage it reaches—that difference is its peak-to-peak value.)\n",
    "\n",
    "**Corr_Z:**\n",
    "- Computes each channel’s mean Pearson correlation to all other channels, then z-scores—so it flags sensors that aren’t co-varying with the head (e.g., drifty or disconnected channels, channels that don't correlate with their neighbours).\n",
    "\n",
    "**Var_Z:**\n",
    "- Takes each channel’s overall variance and z-scores—so it highlights electrodes that are unusually “spiky” or “quiet” over the whole recording (looks at Time domain).\n",
    "\n",
    "**Max_Freq_Z:**\n",
    "- Looks for the largest per-frequency deviation (in z-units) from the grand mean spectrum—so it catches narrowband bursts (line-noise leakage, muscle peaks) that might be lost in the broad PSD average (=For each frequency bin look at how many SD above/below the across-channel mean power that channel’s power is at that exact frequency (i.e. a z-score at 10 Hz, at 20 Hz, etc.), and take whichever of those frequency-specific z-scores is largest in absolute value. That way, even if a channel’s overall PSD looks okay, a single narrowband spike (say a 50 Hz line-noise leak or a muscle peak at 80 Hz) will make its “max_freq_z” jump out.) (looks at Frequency domain).\n",
    "\n",
    "#### Rule of thumb:\n",
    "- If it fails two or more of the checks, probably bad - but do a visual check of PSD and raw trace\n",
    "- Failing one check: Look at PSD and raw trace - if looking good, keep it in\n",
    "\n",
    "**NOTE** Frontal channels can often be flagged, but that is likely because of eyeblinks, so don't necessarily remove them if the raw trace itself looks ok besides the eyeblink!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d943670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# rename for readability\n",
    "bad_chan_identifier = filt_eeg_data.copy().drop_channels(['Fp1', 'Fpz', 'Fp2']) # drop frontal channels because they are often noisy due to eye blinks and this affects the mean/variance computed\n",
    "\n",
    "# pick only the EEG channels that aren’t already in raw.info['bads']\n",
    "picks = mne.pick_types(bad_chan_identifier.info, meg=False, eeg=True, exclude='bads')\n",
    "\n",
    "sfreq = bad_chan_identifier.info['sfreq']\n",
    "\n",
    "# Frequency-domain PSD checks\n",
    "psd_container = bad_chan_identifier.compute_psd(\n",
    "    method=\"welch\",\n",
    "    picks=picks,\n",
    "    fmin=1.0,\n",
    "    fmax=80.0,\n",
    "    n_fft=160,\n",
    "    window=\"hamming\"\n",
    ")\n",
    "\n",
    "# Convert to dB and compute mean PSD per channel\n",
    "psds     = psd_container.get_data()     # (n_picks, n_freqs)\n",
    "psd_db   = 10 * np.log10(psds)\n",
    "mean_psd = psd_db.mean(axis=1)\n",
    "psd_z    = (mean_psd - mean_psd.mean()) / mean_psd.std()\n",
    "\n",
    "# Peak-to-peak amplitude in 250 ms windows\n",
    "data = bad_chan_identifier.get_data(picks=picks)     # (n_picks, n_times)\n",
    "win_samp = int(0.25 * sfreq)\n",
    "n_win    = data.shape[1] // win_samp\n",
    "p2p_mat  = np.zeros((len(picks), n_win))\n",
    "for w in range(n_win):\n",
    "    seg = data[:, w*win_samp:(w+1)*win_samp]\n",
    "    p2p_mat[:, w] = seg.max(axis=1) - seg.min(axis=1)\n",
    "max_p2p = p2p_mat.max(axis=1)\n",
    "p2p_z   = (max_p2p - max_p2p.mean()) / max_p2p.std()\n",
    "\n",
    "# Channel–channel correlation \n",
    "corr      = np.corrcoef(data)\n",
    "mean_corr = corr.mean(axis=0)\n",
    "corr_z    = (mean_corr - mean_corr.mean()) / mean_corr.std()\n",
    "\n",
    "# Compute time-domain variance per channel and z-score\n",
    "# Flags channels with too much or too little amplitude variability over the rec (relative to the other electrodes),\n",
    "# i.e., it could be flat or very spiky\n",
    "chan_vars = np.var(data, axis=1)\n",
    "var_z     = (chan_vars - chan_vars.mean()) / chan_vars.std()\n",
    "\n",
    "# Compute frequency-wise z-scores and max deviation per channel\n",
    "# Looks for channels which have high spikes in some frequencies, could indicate e.g., line noise or muscle artefact\n",
    "mean_freq   = psd_db.mean(axis=0)\n",
    "std_freq    = psd_db.std(axis=0)\n",
    "freq_z      = (psd_db - mean_freq) / std_freq\n",
    "max_freq_z  = np.max(np.abs(freq_z), axis=1)\n",
    "\n",
    "# Threshold all metrics at ±2.5 Z\n",
    "thresh = 2.5\n",
    "mask_psd   = np.abs(psd_z)    > thresh\n",
    "mask_p2p   = np.abs(p2p_z)    > thresh\n",
    "mask_corr  = corr_z           < -thresh    # flag very low corr (z < -2.5)\n",
    "mask_var   = np.abs(var_z)    > thresh\n",
    "mask_freq  = max_freq_z       > thresh\n",
    "\n",
    "# combine\n",
    "mask_all = mask_psd | mask_p2p | mask_corr | mask_var | mask_freq\n",
    "bad_channels = [bad_chan_identifier.ch_names[picks[i]]\n",
    "                for i, m in enumerate(mask_all) if m]\n",
    "\n",
    "# Print per-metric flagged channels\n",
    "print(\">> PSD outliers (|z|>2.5):\", [bad_chan_identifier.ch_names[picks[i]] for i in np.where(mask_psd)[0]])\n",
    "print(\">> Peak-to-peak outliers (|z|>2.5):\", [bad_chan_identifier.ch_names[picks[i]] for i in np.where(mask_p2p)[0]])\n",
    "print(\">> Low-correlation outliers (corr_z < -2.5):\", [bad_chan_identifier.ch_names[picks[i]] for i in np.where(mask_corr)[0]])\n",
    "print(\">> Variance outliers (|z|>2.5):\", [bad_chan_identifier.ch_names[picks[i]] for i in np.where(mask_var)[0]])\n",
    "print(\">> Spectral‐spike outliers (max_freq_z>2.5):\", [bad_chan_identifier.ch_names[picks[i]] for i in np.where(mask_freq)[0]])\n",
    "print(\">> Final flagged channels:\", bad_channels)\n",
    "\n",
    "# Summarize in a DataFrame \n",
    "df = pd.DataFrame({\n",
    "    \"Channel\":     [bad_chan_identifier.ch_names[p]      for p in picks],\n",
    "    \"PSD_Z\":       np.round(psd_z,    2),\n",
    "    \"P2P_Z\":       np.round(p2p_z,    2),\n",
    "    \"Corr_Z\":      np.round(corr_z,   2),\n",
    "    \"Var_Z\":       np.round(var_z,    2),\n",
    "    \"Max_Freq_Z\":  np.round(max_freq_z,2),\n",
    "    \"Flagged\":     mask_all\n",
    "})\n",
    "print(df)\n",
    "\n",
    "# Visual check: all individual PSDs\n",
    "bad_chan_identifier.plot_psd(\n",
    "    fmin=1.0, fmax=80.0,\n",
    "    picks=picks,\n",
    "    dB=True,\n",
    "    average=False,\n",
    "    show=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04e815b",
   "metadata": {},
   "source": [
    "## 3.2. Scrolling through recording and manual removal of \"bad\" channels ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de6ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# Plot raw signal\n",
    "filt_eeg_data.plot(n_channels = len(ch_names), duration = 20, scalings=\"auto\", block=True) # Cell block waits for plot to be closed before continuing (i.e., saving)\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "file_p = join(save_path, f\"{sub.replace(' ', '_')}_artefacts_removed_EEGdata_eeg.fif\")\n",
    "filt_eeg_data.save(file_p, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f12381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure bad channels are listed here, otherwise they will be included in the average reference\n",
    "filt_eeg_data.info['bads']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf98e97",
   "metadata": {},
   "source": [
    "## 3.3. Interpolate bad channels ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d9dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data_interp = filt_eeg_data.copy().interpolate_bads(reset_bads=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5897f691",
   "metadata": {},
   "source": [
    "## 3.4. Re-reference to average ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0743bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_ref_data = []\n",
    "av_ref_data = eeg_data_interp.copy().set_eeg_reference(ref_channels=\"average\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5211b1db",
   "metadata": {},
   "source": [
    "#### Plot PSD again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc1875",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "### Plot PSD of signal (averaging all channels)\n",
    "psd_final_avg = av_ref_data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=1, fmax=130, window=\"hamming\")\n",
    "psd_final_avg.plot(dB=True, average=True).suptitle(f\"{sub} PSD after re-referencing\")\n",
    "plt.show()\n",
    "\n",
    "### Plot PSD of signal (not averaging)\n",
    "psd_final = av_ref_data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=1, fmax=130, window=\"hamming\")\n",
    "psd_final.plot(dB=True, average=False).suptitle(f\"{sub} PSD after re-referencing\")\n",
    "plt.savefig(join(sub_save_path, f\"{sub}_after_reRef.png\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ceed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "av_ref_data.plot(n_channels = len(ch_names), scalings=\"auto\", title=\"After re-referencing to average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab0b03e",
   "metadata": {},
   "source": [
    "# 4. Clean artifacts using Independent Component Analysis #\n",
    "\n",
    "1. Fit ICA to the filtered re-referenced data\n",
    "2. Automatic labelling of \"bad\" components\n",
    "    1. Using mne-icalabel\n",
    "    2. Using eegprep (from Arnaud Delorme)\n",
    "3. Manual labelling of \"bad\" components (and comparison with automatic)\n",
    "4. Select which ICA components to exclude and reconstruct the signal without them\n",
    "\n",
    "\n",
    "**Notes from https://eeglab.org/tutorials/06_RejectArtifacts/RunICA.html:**\n",
    "\n",
    "\"ICA takes all training data into consideration. When too many types (i.e., scalp distributions) of noise - complex movement artifacts, electrode pops, etc – are left in the training data, these unique and irreplicable data features will draw the attention of ICA, producing a set of component maps including many single-channel or noisy-appearing components. The number of components (degrees of freedom) devoted to the decomposition of brain EEG alone will be correspondingly reduced.\n",
    "Therefore, presenting ICA with as much clean EEG data as possible is the best strategy. Note that blink and other stereotyped EEG artifacts do not necessarily have to be removed since they are likely to be isolated as single ICA components.\n",
    "Here clean EEG data means data after removing noisy time segments (does not apply to removed ICA components).\" --> hence, remove breaks before runnning ICA\n",
    "\n",
    "**Random note:**\n",
    "\n",
    "When cognitive load increases, blinking usually decreases. Because when participants are expecting something important to happen (stimulus appearance), they will unconsciously try not to blink, to pay more attention (source: https://www.youtube.com/watch?v=AXCxrDikpaM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d53616",
   "metadata": {},
   "source": [
    "## 4.1. Fit the ICA ##\n",
    "\n",
    "Here we use the extended infomax method, because it is the preferred method for mne-icalabel automatic classification. The ICA must be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dec8166",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_ref_data2 = av_ref_data.copy()\n",
    "break_annot = mne.preprocessing.annotate_break(av_ref_data2, min_break_duration=10, t_start_after_previous=4, t_stop_before_next=4)\n",
    "### Add the breaks to the annotations of the data\n",
    "av_ref_data2 = av_ref_data2.set_annotations(raw.annotations + break_annot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af31470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# Plot signal and annotate bad segments to fit the ICA only on the parts that are the most clean\n",
    "av_ref_data2.plot(n_channels = len(ch_names), duration = 20, scalings=\"auto\", block=True) # Cell block waits for plot to be closed before continuing (i.e., saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4d405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the fitted or loaded ICA objects\n",
    "ica_fit_dict = {}\n",
    " \n",
    "# Construct the file path for the ICA file\n",
    "ica_file_path = join(save_path, f\"{sub}-ica.fif\")\n",
    "    \n",
    "# # Check if the ICA file exists\n",
    "# if os.path.exists(ica_file_path):\n",
    "#     # If it exists, load the ICA object\n",
    "#     ica = read_ica(ica_file_path)\n",
    "#     print(f\"Loaded ICA for {sub} from {ica_file_path}\")\n",
    "\n",
    "# else:\n",
    "# If it doesn't exist, fit ICA to the data\n",
    "ica = ICA(n_components=None, random_state=11, method='infomax', fit_params=dict(extended=True)) # Number of components is chosen by function to account for 99%\n",
    "ica.fit(av_ref_data2.pick_types(eeg=True), reject_by_annotation=True)                                  \n",
    "                         \n",
    "\n",
    "# Save the ICA object to file (saving the ICA decomposition, not any raw/cleaned data)\n",
    "ica.save(ica_file_path, overwrite=True)\n",
    "print(f\"Fitted and saved ICA for {sub} at {ica_file_path}\")\n",
    "    \n",
    "ica_fit_dict = ica\n",
    "\n",
    "for i in range(ica.n_components_):\n",
    "    fig = ica_fit_dict.plot_properties(picks=[i], inst=av_ref_data2, show=False) # Topographies of each component\n",
    "    plt.savefig(join(sub_save_path, f\"{sub}_ica_component_{i}.png\"), dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952f6925",
   "metadata": {},
   "source": [
    "## 4.2. Automatic labelling of \"bad\" components ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760c7764",
   "metadata": {},
   "source": [
    "### 4.2.1. Using mne-icalabel ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb21b15d",
   "metadata": {},
   "source": [
    "Trying automatic labeling using mne-icalabel package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Get automatic classification labels for ICA components using mne-icalabel package (pip install mne-icalabel) to get a first idea\n",
    "ic_labels = label_components(av_ref_data2, ica, method=\"iclabel\")\n",
    "labels = ic_labels[\"labels\"]\n",
    "mne_icalabel_excluded = [\n",
    "    idx for idx, label in enumerate(labels) if label not in [\"brain\", \"other\"]\n",
    "]\n",
    "mne_icalabel_labels = [\n",
    "    (idx, label) for idx, label in enumerate(labels)\n",
    "]\n",
    "print(f\"Excluding these ICA components: {mne_icalabel_excluded}\")\n",
    "\n",
    "ica.plot_properties(av_ref_data2, picks=mne_icalabel_excluded, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f546a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_icalabel_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68543793",
   "metadata": {},
   "source": [
    "### 4.2.2. Using eegprep (from Arnaud Delorme) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033001d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from eegprep import iclabel\n",
    "# EEG = iclabel(av_ref_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f8b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## HERE ADD EEGPREP PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae8770d",
   "metadata": {},
   "source": [
    "## 4.3. Manual labelling of \"bad' ICA components ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2684bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig_sources = ica.plot_sources(av_ref_data2) # Timeseries of each ICA component\n",
    "plt.savefig(join(sub_save_path, f\"{sub}_ica_sources.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e632843",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "fig = ica.plot_components(inst=av_ref_data2,  psd_args={'fmin': 0, 'fmax': 80}, ncols=6, nrows=6) #Topographies of each component\n",
    "plt.savefig(join(sub_save_path, f\"{sub}_ica_components.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa635f2",
   "metadata": {},
   "source": [
    "## 4.4. Select final components to exclude and reconstruct signal ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_exclude = [0, 1, 9, 10, 11, 12, 13, 17, 21, 22, 23]\n",
    "to_exclude = mne_icalabel_excluded.copy()\n",
    "#to_exclude.remove(23)\n",
    "to_exclude.extend([4, 5, 6, 9, 11, 22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da190ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3af4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply ICA to the data\n",
    "data_after_ica = ica.apply(av_ref_data.copy(), exclude=to_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265a64b",
   "metadata": {},
   "source": [
    "# 5. Visual inspection and saving after all preprocessing steps and ICA #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feda663",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "data_after_ica.plot(#n_channels=len(ch_names), \n",
    "    scalings=\"auto\", title=\"After ICA\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fdfc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "### Plot PSD of signal (not averaging)\n",
    "psd_after_ica = data_after_ica.compute_psd(method=\"welch\", picks=\"eeg\", fmin=1, fmax=80, window=\"hamming\")\n",
    "psd_after_ica.plot(dB=True, average=False).suptitle(f\"{sub} PSD after ICA\")\n",
    "plt.savefig(join(sub_save_path, f\"{sub}_after_ICA_PSD.png\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f973b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_p = join(save_path, f\"{sub.replace(' ', '_')}_postICA_EEGdata_eeg.fif\")\n",
    "data_after_ica.save(file_p, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93719ef",
   "metadata": {},
   "source": [
    "# 6. ADDITIONAL: visualize STFT of all channels #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c4601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ch_names_data = data_after_ica.info['ch_names']\n",
    "eeg_data = data_after_ica.get_data(picks='eeg')\n",
    "eeg_times = data_after_ica.times\n",
    "\n",
    "ch_names_data.remove('BIP 02')\n",
    "ch_names_data.remove('BIP 03')\n",
    "\n",
    "vmin, vmax = -17, -13\n",
    "\n",
    "for ch in ch_names_data:\n",
    "    ch_index = ch_names_data.index(ch)\n",
    "\n",
    "    f, t, Zxx = scipy.signal.stft(\n",
    "        eeg_data[ch_index, :], raw.info['sfreq'], nperseg=int(round(raw.info['sfreq'])), noverlap=int(round(raw.info['sfreq']) / 2), nfft=int(round(raw.info['sfreq']))\n",
    "    )\n",
    "    Pxx = np.abs(Zxx)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    im = plt.imshow(np.log(Pxx), aspect='auto', origin='lower',\n",
    "                            extent=[t[0], t[-1], f[0], f[-1]], cmap='viridis',\n",
    "                            vmin=vmin, vmax=vmax)\n",
    "    plt.ylim(0,100)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.title(f'{session_id} - EEG - {ch}')\n",
    "    #plt.savefig(os.path.join(fig_saving_path, f\"{session_id}_{ch}_STFT.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda58920",
   "metadata": {},
   "source": [
    "# 7. ADDITIONAL: Extract epochs to check data quality after ICA and plot specific channels: \n",
    "C3/C4 channels are the ones above the motor cortex, they can be plotted to check that the expected beta desynchronization is visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1241199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if cleaning was already done, load data_after_ica file here:\n",
    "results_path = os.path.join(working_path, \"results\")\n",
    "saving_path = os.path.join(results_path, session_id)\n",
    "source_path = os.path.join(saving_path, \"data\")\n",
    "file_p = os.path.join(source_path, f\"{sub}_postICA_EEGdata_eeg.fif\")\n",
    "fig_saving_path = os.path.join(saving_path, \"figures\", \"test new cleaning\")\n",
    "if not os.path.exists(fig_saving_path):\n",
    "    os.makedirs(fig_saving_path)\n",
    "\n",
    "# Load fif file\n",
    "data_after_ica = mne.io.read_raw_fif(file_p, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b8cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mSST_raw_behav_session_data_path = join(\n",
    "        onedrive_path, sub, \"raw_data\", 'BEHAVIOR', condition, 'mSST'\n",
    "        )\n",
    "for filename in os.listdir(mSST_raw_behav_session_data_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            fname = filename\n",
    "filepath_behav = join(mSST_raw_behav_session_data_path, fname)\n",
    "df = pd.read_csv(filepath_behav)\n",
    "\n",
    "# return the index of the first row which is not filled by a Nan value:\n",
    "start_task_index = df['blocks.thisRepN'].first_valid_index()\n",
    "stop_task_index = df['blocks.thisRepN'].last_valid_index()\n",
    "df_maintask = df.iloc[start_task_index:stop_task_index + 1] ### HERE MISTAKE OF INDEXING: CHECK IN OTHER SCRIPTS IF THIS IS ALSO WRONG!!!\n",
    "\n",
    "# remove all useless columns to clean up dataframe\n",
    "column_names = df_maintask.columns\n",
    "columns_to_keep = [i for i in [\n",
    "    'blocks.thisN', 'trial_loop.thisN', 'trial_type', \n",
    "    'continue_signal_time', 'stop_signal_time', \n",
    "    'fixation_cross.started', 'go_rectangle.started',\n",
    "    'key_resp_experiment.keys', 'key_resp_experiment.corr', 'key_resp_experiment.rt',\n",
    "    'early_press_resp.keys', 'early_press_resp.rt', 'early_press_resp.corr',\n",
    "    'late_key_resp1.keys', 'late_key_resp1.rt', \n",
    "    'late_key_resp2.keys', 'late_key_resp2.rt'\n",
    "    ] if i in column_names]\n",
    "\n",
    "mini_df_maintask = df_maintask[columns_to_keep]\n",
    "print(mini_df_maintask.shape)\n",
    "\n",
    "# remove the trials with early presses, as in these trials the cues were not presented (for mSST)\n",
    "early_presses = mini_df_maintask[mini_df_maintask['early_press_resp.corr'] == 1]\n",
    "early_presses_trials = list(early_presses.index)\n",
    "number_early_presses = len(early_presses_trials)\n",
    "print(f'Number of early presses: {number_early_presses}')\n",
    "\n",
    "# remove trials with early presses from the dataframe:\n",
    "df_maintask_copy = mini_df_maintask.drop(early_presses_trials).reset_index(drop=True)\n",
    "print(df_maintask_copy.shape)\n",
    "print(df_maintask_copy['blocks.thisN'])\n",
    "\n",
    "# First generate global epochs (without taking into account success outcome)\n",
    "# events and event_id used for epochs creation\n",
    "events, event_id = mne.events_from_annotations(data_after_ica)\n",
    "epochs, filtered_event_dict = preprocessing.create_epochs(\n",
    "        data_after_ica, \n",
    "        sub, \n",
    "        keys_to_keep = ['GC', 'GF', 'GO', 'GS', 'continue', 'stop'],\n",
    "        tmin = -3.5,\n",
    "        tmax = 3.5,\n",
    "        baseline=None\n",
    "        )\n",
    "n_epochs = len(epochs)\n",
    "print(epochs)\n",
    "\n",
    "# inverse mapping (event code -> label)\n",
    "inv_event_id = {v: k for k, v in event_id.items()}\n",
    "\n",
    "metadata = pd.DataFrame(index=np.arange(len(epochs)))\n",
    "metadata[\"event\"] = [inv_event_id[e] for e in epochs.events[:, 2]]\n",
    "metadata[\"sample\"] = epochs.events[:, 0]\n",
    "metadata[\"event_timing\"] = epochs.events[:, 0] / raw.info['sfreq']  # in seconds\n",
    "metadata[\"trial_type\"] = np.nan\n",
    "\n",
    "# LFP -> behavioral naming mapping\n",
    "mapping = {\n",
    "    \"GC\": \"go_continue_trial\",\n",
    "    \"GO\": \"go_trial\",\n",
    "    \"GF\": \"go_fast_trial\",\n",
    "    \"GS\": \"stop_trial\",\n",
    "}\n",
    "\n",
    "trial_mask = metadata[\"event\"].isin(mapping.keys())\n",
    "\n",
    "assert trial_mask.sum() == len(df_maintask_copy), \\\n",
    "    f\"Mismatch: {trial_mask.sum()} LFP trials vs {len(df_maintask_copy)} behavioral trials\"\n",
    "\n",
    "# fill directly from behavioral file\n",
    "for col in df_maintask_copy.columns:\n",
    "    metadata.loc[trial_mask, col] = df_maintask_copy[col].values\n",
    "\n",
    "for i in metadata.index:\n",
    "    if metadata.loc[i, \"event\"] == \"continue\":\n",
    "        # find the last GC before this\n",
    "        prev_idx = metadata.loc[:i-1][metadata[\"event\"] == \"GC\"].index[-1]\n",
    "        metadata.loc[i, df_maintask_copy.columns] = metadata.loc[prev_idx, df_maintask_copy.columns]\n",
    "\n",
    "    elif metadata.loc[i, \"event\"] == \"stop\":\n",
    "        # find the last GS before this\n",
    "        prev_idx = metadata.loc[:i-1][metadata[\"event\"] == \"GS\"].index[-1]\n",
    "        metadata.loc[i, df_maintask_copy.columns] = metadata.loc[prev_idx, df_maintask_copy.columns]\n",
    "\n",
    "epochs.metadata = metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc622a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e919a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# Generate list of evoked objects from conditions names\n",
    "evokeds = [epochs[name].crop(tmin=-0.5, tmax=1.5).average() for name in (\"GO\", \"GF\",\"GC\", \"GS\")]\n",
    "colors = \"blue\", \"red\", \"green\", \"black\"\n",
    "title = \"Evoked responses\"\n",
    "\n",
    "fig, axes = plt.subplots(1)\n",
    "\n",
    "mne.viz.plot_evoked_topo(evokeds, title=title, background_color=\"w\", axes=axes)\n",
    "\n",
    "fig.savefig(join(saving_path, 'evoked_responses.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecba114",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "### TFR PARAMETERS ###\n",
    "######################\n",
    "\n",
    "decim = 1 \n",
    "freqs = np.arange(1, 80, 1) \n",
    "# For 500ms time resolution at 1 Hz: n_cycles = 1 * 0.5 = 0.5\n",
    "# For 50ms time resolution at 40 Hz: n_cycles = 40 * 0.05 = 2\n",
    "# Linear interpolation between these points\n",
    "#n_cycles = 0.5 + (freqs - 1) * (2 - 0.5) / (40 - 1)\n",
    "#n_cycles = freqs / 2.0\n",
    "n_cycles = np.minimum(np.maximum(freqs / 2.0, 2), 10)\n",
    "\n",
    "tfr_args = dict(\n",
    "    method=\"morlet\",\n",
    "    freqs=freqs,\n",
    "    n_cycles=n_cycles,\n",
    "    decim=decim,\n",
    "    return_itc=False,\n",
    "    average=False\n",
    ")        \n",
    "\n",
    "tmin_tmax = [-500, 1500]\n",
    "vmin_vmax = [-70, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0ed487",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "epochs.plot(n_channels = 32, n_epochs = 4, events=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ca5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for epoch_cond in ['GO_successful', 'GF_successful', 'GC_successful', 'GS_successful', 'GS_unsuccessful']:\n",
    "    ch_interest = \"Cz\"\n",
    "\n",
    "    t_min_max = [-500, 1500]\n",
    "\n",
    "    epoch_type = epoch_cond.split('_')[0]\n",
    "    outcome_str = epoch_cond.split('_')[1]\n",
    "\n",
    "    outcome = 1.0 if outcome_str == 'successful' else 0.0\n",
    "\n",
    "    type_mask = epochs.metadata[\"event\"] == epoch_type\n",
    "    outcome_mask = epochs.metadata[\"key_resp_experiment.corr\"] == outcome\n",
    "    data = epochs[type_mask & outcome_mask]   \n",
    "\n",
    "    channel_epochs = data.copy().pick([ch_interest])\n",
    "    power_channel = channel_epochs.compute_tfr(**tfr_args)\n",
    "    mean_power_channel = np.nanmean(power_channel.data, axis=0).squeeze()\n",
    "\n",
    "    times = power_channel.times * 1000  # Convert to milliseconds\n",
    "    freqs = power_channel.freqs\n",
    "\n",
    "    baseline_indices = (times >= -500) & (times <= -200)\n",
    "    baseline_power_channel = np.nanmean(mean_power_channel[:, baseline_indices], axis=1, keepdims=True)\n",
    "    percentage_change_channel = (mean_power_channel - baseline_power_channel) / baseline_power_channel * 100\n",
    "\n",
    "    time_indices = np.logical_and(times >= t_min_max[0], times <= t_min_max[1])\n",
    "    sliced_data = percentage_change_channel[:, time_indices].squeeze()    \n",
    "\n",
    "    plt.imshow(sliced_data, aspect='auto', origin='lower', \n",
    "            extent=[t_min_max[0], t_min_max[1], \n",
    "            tfr_args[\"freqs\"][0], tfr_args[\"freqs\"][-1]], \n",
    "            cmap='jet', vmin=vmin_vmax[0], vmax=vmin_vmax[-1]\n",
    "    )\n",
    "    plt.axvline(x=0, color='k', linestyle='--', linewidth=1)\n",
    "    plt.title(f\"Percentage Change in Power for {epoch_cond} - {ch_interest}\")\n",
    "    plt.xlabel(\"Time from GO cue (ms)\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.colorbar(label=\"Percentage Change (%)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ef72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "evokeds_go = epochs['GO'].crop(tmin=-0.5, tmax=1.5).average()\n",
    "evokeds_gf = epochs['GF'].crop(tmin=-0.5, tmax=1.5).average()\n",
    "evokeds_gc = epochs['GC'].crop(tmin=-0.5, tmax=1.5).average()\n",
    "evokeds_gs = epochs['GS'].crop(tmin=-0.5, tmax=1.5).average()\n",
    "\n",
    "evokeds = [evokeds_go, evokeds_gf, evokeds_gc, evokeds_gs]\n",
    "colors = \"blue\", \"red\", \"green\", \"black\"\n",
    "title = \"Evoked responses\"\n",
    "\n",
    "fig, axes = plt.subplots(1)\n",
    "\n",
    "mne.viz.plot_evoked_topo(evokeds, title=title, background_color=\"w\", axes=axes)\n",
    "\n",
    "fig.savefig(join(saving_path, 'evoked_responses.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66a3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict_trials = {\n",
    "    \"GO_successful\": (\"green\", 0.5), \n",
    "    \"GS_successful\": (\"red\", 0.5),\n",
    "    \"GS_unsuccessful\": (\"orange\", 0.5),\n",
    "    \"GF_successful\": (\"black\", 0.5),\n",
    "    \"GC_successful\": (\"blue\", 0.5)\n",
    "    }\n",
    "\n",
    "# compare conditions 2 by 2:\n",
    "conditions = {'successful versus unsuccessful stopping': ('GS_successful', 'GS_unsuccessful'),\n",
    "               'successful stopping versus going': (\"GO_successful\", \"GS_successful\"),\n",
    "               'successful GF versus GO': (\"GO_successful\", \"GF_successful\")\n",
    "               }\n",
    "\n",
    "for key, value in conditions.items():\n",
    "    epoch_type_1 = value[0].split('_')[0]\n",
    "    outcome_str_1 = value[0].split('_')[1]\n",
    "\n",
    "    outcome1 = 1.0 if outcome_str_1 == 'successful' else 0.0\n",
    "\n",
    "    type_mask = epochs.metadata[\"event\"] == epoch_type_1\n",
    "    outcome_mask = epochs.metadata[\"key_resp_experiment.corr\"] == outcome1\n",
    "    epochs_cond1 = epochs[type_mask & outcome_mask]\n",
    "    evokeds_cond1 = epochs_cond1.crop(tmin=-0.5, tmax=1.5).average()\n",
    "\n",
    "    epoch_type_2 = value[1].split('_')[0]\n",
    "    outcome_str_2 = value[1].split('_')[1]\n",
    "    outcome2 = 1.0 if outcome_str_2 == 'successful' else 0.0\n",
    "\n",
    "    type_mask = epochs.metadata[\"event\"] == epoch_type_2\n",
    "    outcome_mask = epochs.metadata[\"key_resp_experiment.corr\"] == outcome2\n",
    "    epochs_cond2 = epochs[type_mask & outcome_mask]\n",
    "    evokeds_cond2 = epochs_cond2.crop(tmin=-0.5, tmax=1.5).average()\n",
    "\n",
    "    evokeds = [evokeds_cond1, evokeds_cond2]\n",
    "    # Update comments for legend labels\n",
    "    evokeds_cond1.comment = value[0]\n",
    "    evokeds_cond2.comment = value[1]\n",
    "    colors = color_dict_trials[value[0]], color_dict_trials[value[1]]\n",
    "    title = f\"Evoked responses: {key}\"\n",
    "\n",
    "    fig, axes = plt.subplots(1)\n",
    "\n",
    "    mne.viz.plot_evoked_topo(evokeds, color=colors, title=title, background_color=\"w\", axes=axes, legend=True)\n",
    "\n",
    "    fig.savefig(join(saving_path, f'evoked_responses_{key.replace(\" \", \"_\")}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d3b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.stats import permutation_cluster_test\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# look for statistical differences at specific channels of interest:\n",
    "color_dict_trials = {\n",
    "    \"GO_successful\": (\"green\", 0.5), \n",
    "    \"GS_successful\": (\"red\", 0.5),\n",
    "    \"GS_unsuccessful\": (\"orange\", 0.5),\n",
    "    \"GF_successful\": (\"black\", 0.5),\n",
    "    \"GC_successful\": (\"blue\", 0.5),\n",
    "    \"STOP_successful\": (\"red\", 0.5),\n",
    "    \"STOP_unsuccessful\": (\"orange\", 0.5),    \n",
    "    }\n",
    "\n",
    "# compare conditions 2 by 2:\n",
    "conditions = {'successful versus unsuccessful stopping': ('GS_successful', 'GS_unsuccessful'),\n",
    "               'successful stopping versus going': (\"GO_successful\", \"GS_successful\"),\n",
    "               'successful GF versus GO': (\"GO_successful\", \"GF_successful\")\n",
    "               }\n",
    "channels_of_interest = ['Cz', 'C3', 'C4']  \n",
    "\n",
    "for ch_name in channels_of_interest:\n",
    "    for key, value in conditions.items():\n",
    "        epoch_type_1 = value[0].split('_')[0]\n",
    "        outcome_str_1 = value[0].split('_')[1]\n",
    "\n",
    "        outcome1 = 1.0 if outcome_str_1 == 'successful' else 0.0\n",
    "\n",
    "        type_mask = epochs.metadata[\"event\"] == epoch_type_1\n",
    "        outcome_mask = epochs.metadata[\"key_resp_experiment.corr\"] == outcome1\n",
    "        epochs_cond1 = epochs[type_mask & outcome_mask].crop(tmin=-0.5, tmax=1.5)\n",
    "\n",
    "        epoch_type_2 = value[1].split('_')[0]\n",
    "        outcome_str_2 = value[1].split('_')[1]\n",
    "        outcome2 = 1.0 if outcome_str_2 == 'successful' else 0.0\n",
    "\n",
    "        type_mask = epochs.metadata[\"event\"] == epoch_type_2\n",
    "        outcome_mask = epochs.metadata[\"key_resp_experiment.corr\"] == outcome2\n",
    "        epochs_cond2 = epochs[type_mask & outcome_mask].crop(tmin=-0.5, tmax=1.5)\n",
    "\n",
    "        # Pick Cz channel index\n",
    "        ch_idx = epochs.ch_names.index(ch_name)\n",
    "\n",
    "        # Get data for both conditions: (n_epochs, n_channels, n_times)\n",
    "        data1 = epochs_cond1.get_data()  # condition 1\n",
    "        data2 = epochs_cond2.get_data()  # condition 2\n",
    "\n",
    "        # Extract Cz channel only: (n_epochs, n_times)\n",
    "        data1_ch = data1[:, ch_idx, :]\n",
    "        data2_ch = data2[:, ch_idx, :]\n",
    "\n",
    "        # Compute mean and std across trials\n",
    "        mean1 = data1_ch.mean(axis=0)\n",
    "        std1 = data1_ch.std(axis=0)\n",
    "        mean2 = data2_ch.mean(axis=0)\n",
    "        std2 = data2_ch.std(axis=0)\n",
    "\n",
    "        # Time vector\n",
    "        times = epochs_cond1.times\n",
    "\n",
    "        # -------------------\n",
    "        # Cluster-based permutation test\n",
    "        # -------------------\n",
    "        X = [data1_ch, data2_ch]  # two conditions\n",
    "        T_obs, clusters, cluster_p_values, H0 = permutation_cluster_test(\n",
    "            X, n_permutations=1000, tail=0, n_jobs=1, out_type=\"mask\"\n",
    "        )\n",
    "\n",
    "        # -------------------\n",
    "        # Plot\n",
    "        # -------------------\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        # Plot condition 1 with variance\n",
    "        plt.plot(times, mean1, color='red', label=value[0])\n",
    "        plt.fill_between(times, mean1 - std1, mean1 + std1, color='red', alpha=0.3)\n",
    "\n",
    "        # Plot condition 2 with variance\n",
    "        plt.plot(times, mean2, color='blue', label=value[1])\n",
    "        plt.fill_between(times, mean2 - std2, mean2 + std2, color='blue', alpha=0.3)\n",
    "\n",
    "        # Mark significant clusters (p < 0.05)\n",
    "        for cluster_idx, cluster in enumerate(clusters):\n",
    "            if cluster_p_values[cluster_idx] < 0.05:\n",
    "                # cluster is a boolean array of time points\n",
    "                cluster_times = times[cluster]\n",
    "                plt.axvspan(cluster_times[0], cluster_times[-1], color='grey', alpha=0.3)\n",
    "\n",
    "        plt.axvline(0, color='k', linestyle='--', linewidth=1)\n",
    "        plt.title(f\"{ch_name}: {value[0]} vs {value[1]} (cluster-based permutation)\")\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"Amplitude (µV)\")\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c55838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "color_dict_trials = {\n",
    "    \"GO_successful\": (\"green\", 0.5), \n",
    "    \"GS_successful\": (\"red\", 0.5),\n",
    "    \"GS_unsuccessful\": (\"orange\", 0.5),\n",
    "    \"GF_successful\": (\"black\", 0.5),\n",
    "    \"GC_successful\": (\"blue\", 0.5),\n",
    "    \"stop_successful\": (\"red\", 0.5),\n",
    "    \"stop_unsuccessful\": (\"orange\", 0.5),    \n",
    "}\n",
    "\n",
    "conditions = {'successful STOP versus unsuccessful STOP': ('stop_successful', 'stop_unsuccessful')}\n",
    "\n",
    "n2_window = (0.200, 0.300)\n",
    "p3_window = (0.300, 0.450)\n",
    "n2_channels = [\"Fz\", \"Cz\"]\n",
    "p3_channels = [\"Cz\", \"Pz\"]\n",
    "\n",
    "results = []\n",
    "evoked_dict = {}\n",
    "\n",
    "for key, value in conditions.items():\n",
    "    for cond_name in value:\n",
    "        epoch_type = cond_name.split('_')[0]\n",
    "        outcome_str = cond_name.split('_')[1]\n",
    "        outcome = 1.0 if outcome_str == 'successful' else 0.0\n",
    "\n",
    "        type_mask = epochs.metadata[\"event\"] == epoch_type\n",
    "        outcome_mask = epochs.metadata[\"key_resp_experiment.corr\"] == outcome\n",
    "        epochs_cond = epochs[type_mask & outcome_mask].crop(tmin=-0.5, tmax=1.5)\n",
    "\n",
    "        evoked = epochs_cond.average()\n",
    "        evoked_dict[cond_name] = evoked\n",
    "\n",
    "        times = evoked.times\n",
    "        n2_data = evoked.copy().pick_channels(n2_channels).data.mean(axis=0)\n",
    "        p3_data = evoked.copy().pick_channels(p3_channels).data.mean(axis=0)\n",
    "\n",
    "        # N2 peak\n",
    "        n2_mask = (times >= n2_window[0]) & (times <= n2_window[1])\n",
    "        n2_segment = n2_data[n2_mask]\n",
    "        n2_times_segment = times[n2_mask]\n",
    "        n2_peak_idx = np.argmin(n2_segment)\n",
    "        n2_peak_time = n2_times_segment[n2_peak_idx]\n",
    "        n2_amplitude = n2_data[(times >= n2_peak_time - 0.010) & (times <= n2_peak_time + 0.010)].mean()\n",
    "\n",
    "        # P3 peak\n",
    "        p3_mask = (times >= p3_window[0]) & (times <= p3_window[1])\n",
    "        p3_segment = p3_data[p3_mask]\n",
    "        p3_times_segment = times[p3_mask]\n",
    "        p3_peak_idx = np.argmax(p3_segment)\n",
    "        p3_peak_time = p3_times_segment[p3_peak_idx]\n",
    "        p3_amplitude = p3_data[(times >= p3_peak_time - 0.010) & (times <= p3_peak_time + 0.010)].mean()\n",
    "\n",
    "        results.append({\n",
    "            \"condition\": cond_name,\n",
    "            \"comparison\": key,\n",
    "            \"N2_peak_time\": n2_peak_time,\n",
    "            \"N2_amplitude\": n2_amplitude,\n",
    "            \"P3_peak_time\": p3_peak_time,\n",
    "            \"P3_amplitude\": p3_amplitude\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)\n",
    "\n",
    "# -----------------------\n",
    "# PLOT 1: N2 (Fz + Cz)\n",
    "# -----------------------\n",
    "cond1, cond2 = conditions[list(conditions.keys())[0]]\n",
    "evoked1 = evoked_dict[cond1]\n",
    "evoked2 = evoked_dict[cond2]\n",
    "\n",
    "n2_data1 = evoked1.copy().pick_channels(n2_channels).data.mean(axis=0) * 1e6\n",
    "n2_data2 = evoked2.copy().pick_channels(n2_channels).data.mean(axis=0) * 1e6\n",
    "times = evoked1.times\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(times, n2_data1, color=color_dict_trials[cond1][0], label=f\"{cond1}\")\n",
    "plt.plot(times, n2_data2, color=color_dict_trials[cond2][0], label=f\"{cond2}\")\n",
    "plt.axvspan(n2_window[0], n2_window[1], color='grey', alpha=0.2, label=\"N2 window\")\n",
    "plt.axvline(0, color='k', linestyle='--')\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude (µV)\")\n",
    "plt.title(f\"N2 Component (Channels: {', '.join(n2_channels)})\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------\n",
    "# PLOT 2: P3 (Cz + Pz)\n",
    "# -----------------------\n",
    "p3_data1 = evoked1.copy().pick_channels(p3_channels).data.mean(axis=0) * 1e6\n",
    "p3_data2 = evoked2.copy().pick_channels(p3_channels).data.mean(axis=0) * 1e6\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(times, p3_data1, color=color_dict_trials[cond1][0], label=f\"{cond1}\")\n",
    "plt.plot(times, p3_data2, color=color_dict_trials[cond2][0], label=f\"{cond2}\")\n",
    "plt.axvspan(p3_window[0], p3_window[1], color='grey', alpha=0.2, label=\"P3 window\")\n",
    "plt.axvline(0, color='k', linestyle='--')\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude (µV)\")\n",
    "plt.title(f\"P3 Component (Channels: {', '.join(p3_channels)})\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ab604b",
   "metadata": {},
   "source": [
    "### Note\n",
    "Once each subject has been preprocessed and epochs cleaned, other scripts will load the cleaned epochs and run the analyses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ephy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
