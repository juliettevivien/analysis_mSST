{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f4d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT EXTERNAL FUNCTIONS\n",
    "import mne\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.preprocessing import ICA, read_ica\n",
    "from mne_icalabel import label_components\n",
    "from collections import defaultdict\n",
    "\n",
    "os.getcwd()\n",
    "import functions.io as io\n",
    "import functions.utils as utils\n",
    "import functions.preprocessing as preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c39c618",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "- Loads data (single sub)\n",
    "- Checks unit of raw data (without any manipulation of raw, just checking)\n",
    "- Dropping channels that aren't of interest, and setting channel types (you will want to keep X.Y,Z channels though!)\n",
    "- Re-scales data and replaces raw (if check above suggests that data is in \"raw units ADC\" from amplifier. If one needs to be rescaled all do, but I keep the check in here just so I/we know what's going on and why we're rescaling)\n",
    "- Set montage (so that each electrode has it's location when we use scalp tophographies for visualisations and electrode placement (and later for other stuff I assume))\n",
    "- High- and low-pass filter + notch filter\n",
    "- Annotate breaks, so that beginning, breaks between blocks, and end isn't included in the analyses. I found that if we crop the event timings get shifted, if we just annotate here then we don't shift any times and events around, and the \"bad\" parts are not included in analyses.\n",
    "- Plot raw trace and manually annotate bad parts of raw trace (I think only the most obvious movements/artefacts with huge shifts amplitude). Annotating can be done when seeing raw traces interactivately, click \"a\" on keybord to get the \"helper/info\" and then type \"movement\" straight away and hit enter. This creates a new \"marker\" which you then use to mark bad segments (click and drag over the bad segments). Also remove obviously bad channels here (more info at that stage).\n",
    "- Following this, when the obviously bad movements/artefacts/channels are removed, we can run some checks on channels to check if they are likely to be bad or not - see more info at that point in the notebook. I still don't know what's \"appropriate\" to do here, but the code is there if useful, and if the results can be used to guide selection of channels?\n",
    "- After all removal -> re-reference to average\n",
    "- Run ICA and save it so I don't need to re-run it later (if everything is identical in preprocessing), but can load it and apply it to the data again with e.g., other components removed etc. \n",
    "- Plot ICA components to see topographies, time series of components, how much variance is explained by the components etc (I don't really understand this variance fully, what is good and what is bad? Is there a good and bad?). Then some mne functions that \"automatically\" suggests which components are likely to be ECG, EOG, and mostly muscle noise. I think for now i prefer to do it manually, and use these checks as guides and compare to what I think the components are - see more notes at that point in the notebook.\n",
    "- Select bad components and remove them \n",
    "- Apply the ICA to data\n",
    "- After this the preprocessing of raw data is done. \n",
    "\n",
    "\n",
    "I then have parts where I epoch the data, and then remove bad epochs (the parts I have previously marked as bad are still in the data, because when I load the epochs I tell it to also include what segments of the raw trace I marked as bad to be excluded. I found that if I exclude the \"bad_movement\" I marked manually before ICA, all my epoch indexes are shifted because parts of the data has been removed, so the behavioural file index and actual remaining data indexes are not matching and I'm pulling the wrong epochs in my extract epoch functions. By keeping the \"bad_movement\" data in when I extract epochs, no data is removed when epochs are created, so I will have to quickly go over and just remove those that are bad again). This could probably be done in a smoother way, but I don't find this too annyoing to do, at epoch level it doesn't take too long to quickly scan through. \n",
    "\n",
    "\n",
    "I plot (and save) PSDs regularly to see what the impact the different preprocessing steps have. Might not be necessary later on - but for now i find it ok. \n",
    "I also save the file after some steps (it is marked when saved), so that the steps that takes long/are tedious don't have to be re-done all the time if wanting to test different methods etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae28d814",
   "metadata": {},
   "source": [
    "# 1. Load dataset and prepare for pre-processing #\n",
    "\n",
    "1. Load one EEG raw dataset and its associated impedances files\n",
    "2. Change channel types to match recording setup & remove unnecessary channels (like TRIGGERS, STATUS, ETC.)\n",
    "3. Apply the 10-20 montage to EEG recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00371ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session to preprocess\n",
    "session_id = \"sub006 DBS OFF mSST\"\n",
    "\n",
    "working_path = os.path.dirname(os.getcwd())\n",
    "onedrive_path = utils._get_onedrive_path()\n",
    "\n",
    "sub = session_id.split(' ') [0]\n",
    "condition = session_id.split(' ') [1] + ' ' + session_id.split(' ') [2]\n",
    "sub_onedrive_path_task = join(onedrive_path, sub, 'synced_data', session_id)\n",
    "\n",
    "#  Set saving path\n",
    "results_path = join(working_path, \"results\")\n",
    "saving_path = join(results_path, session_id)\n",
    "if not os.path.isdir(saving_path):\n",
    "    os.makedirs(saving_path)\n",
    "sub_save_path = join(saving_path, \"sub_data\", f\"{sub}\", \"figures\")\n",
    "os.makedirs(sub_save_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "save_path = os.path.join(saving_path, \"sub_data\", f\"{sub}\", \"data\")\n",
    "os.makedirs(save_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# Load raw data\n",
    "filename = [f for f in os.listdir(sub_onedrive_path_task) if (\n",
    "    f.endswith('.set') and f.startswith('SYNCHRONIZED_EXTERNAL'))]\n",
    "file = join(sub_onedrive_path_task, filename[0])\n",
    "raw = mne.io.read_raw(file, preload=True)\n",
    "\n",
    "# also load the two impedance files to check channels briefly\n",
    "impedance_folder = join(onedrive_path, sub, 'raw_data', 'XDF', condition)\n",
    "impedance_begin_filename = [f for f in os.listdir(impedance_folder) if (\n",
    "    f.endswith('.txt') and f.startswith('mSST_impedances_begin'))]\n",
    "impedance_end_filename = [f for f in os.listdir(impedance_folder) if (\n",
    "    f.endswith('.txt') and f.startswith('mSST_impedances_end'))]\n",
    "file_begin = join(impedance_folder, impedance_begin_filename[0])\n",
    "file_end = join(impedance_folder, impedance_end_filename[0])\n",
    "impedance_begin = pd.read_csv(file_begin, sep='\\t', header=None)\n",
    "impedance_end = pd.read_csv(file_end, sep='\\t', header=None)\n",
    "impedance_begin.drop(2, axis=1, inplace=True)  \n",
    "impedance_end.drop(2, axis=1, inplace=True)\n",
    "imp = impedance_begin.merge(impedance_end, on=0, how='outer', suffixes=('_begin', '_end'))\n",
    "# remove all rows starting with 'UNI':\n",
    "imp = imp[~imp[0].str.startswith('UNI')]\n",
    "\n",
    "# flag channels with impedance above 25 kOhm:\n",
    "high_imp_channels = imp[(imp['1_begin'] > 25) | (imp['1_end'] > 25)]\n",
    "if not high_imp_channels.empty:\n",
    "    print(\"Channels with high impedance (> 25 kOhm):\")\n",
    "    print(high_imp_channels)\n",
    "else:\n",
    "    print(\"No channels with high impedance found.\")\n",
    "\n",
    "sf = raw.info['sfreq']\n",
    "print(f\"Sampling frequency: {sf} Hz\")\n",
    "\n",
    "raw.drop_channels(['CREF', 'X', 'Y', 'Z', 'TRIGGERS', 'STATUS', 'COUNTER', 'BIP 01'])\n",
    "raw.set_channel_types({'BIP 02': 'ecg', 'BIP 03': 'eog'}) \n",
    "\n",
    "# set 10-20 montage\n",
    "data = raw.set_montage('standard_1020', match_case=False, match_alias=True, on_missing='warn') \n",
    "ch_names = data.ch_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12473b7",
   "metadata": {},
   "source": [
    "#### Plot raw PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc91e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "### Plot PSD of signal (averaging all channels)\n",
    "psd_raw_avg = data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=0, fmax=130, n_fft=round(sf)*2, n_overlap=int(round(sf)), window=\"hamming\")\n",
    "psd_raw_avg.plot(dB=True, average=True).suptitle(f\"Raw PSD {sub}\")\n",
    "plt.show()\n",
    "\n",
    "### Plot PSD of signal (not averaging)\n",
    "psd_raw = data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=0, fmax=130, n_fft=round(sf)*2, n_overlap=int(round(sf)), window=\"hamming\")\n",
    "psd_raw.plot(dB=True, average=False).suptitle(f\"Raw PSD {sub}\")\n",
    "plt.savefig(join(sub_save_path, f\"{sub}_raw_PSD_avg.png\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a440b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "data.plot(n_channels = len(ch_names), scalings=\"auto\", title=\"Raw data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb3a2e9",
   "metadata": {},
   "source": [
    "# 2. Filter the data #\n",
    "\n",
    "1. Apply high-pass filter at 1Hz to remove slow-drifts\n",
    "2. Apply low-pass filter at 80Hz to remove DBS main artifact and only keep frequencies of interest for futher analysis\n",
    "3. Apply notch filter at 50Hz to remove line noise\n",
    "4. Additionnally if another artifactual peak is visible in the PSD (aliased stimulation frequency...), add another notch-filter around it to dampen it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752322ae",
   "metadata": {},
   "source": [
    "## 2.1. COMMON filtering steps: High- and low-pass filtering + notch ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd67658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first apply 1Hz high pass filter\n",
    "high_passed_filt_eeg_data = data.copy().filter(1, None) \n",
    "\n",
    "# then apply 80Hz low pass filter\n",
    "high_low_passed_filt_eeg_data = high_passed_filt_eeg_data.copy().filter(None, 80) \n",
    "\n",
    "# Last, apply notch filter(s)\n",
    "# Even if 50Hz activity is not present in the raw, it is sometimes present after re-referencing\n",
    "# Therefore, it is safer to apply a notch filter at 50Hz for all sessions.\n",
    "filt_eeg_data = high_low_passed_filt_eeg_data.copy().notch_filter(50) \n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "### Plot PSD of signal (averaging all channels)\n",
    "psd_filt_avg = filt_eeg_data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=0, fmax=100, n_fft=round(sf)*2, n_overlap=int(round(sf)), window=\"hamming\")\n",
    "psd_filt_avg.plot(dB=True, average=True).suptitle(f\"{sub} Filtered PSD\")\n",
    "plt.show()\n",
    "\n",
    "### Plot PSD of signal (not averaging)\n",
    "psd_filt = filt_eeg_data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=0, fmax=100, n_fft=round(sf)*2, n_overlap=int(round(sf)), window=\"hamming\")\n",
    "psd_filt.plot(dB=True, average=False).suptitle(f\"{sub} Filtered PSD\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce92c7f",
   "metadata": {},
   "source": [
    "## 2.2. SPECIFIC step: filter out potential other artifacts ##\n",
    "\n",
    "e.g. in our recordings at 2048Hz, we commonly see a peak at 48Hz coming from the aliasing of the 16th harmonic of 125Hz DBS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0428d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_eeg_data.notch_filter(48)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc4f227",
   "metadata": {},
   "source": [
    "# 3. Identify and interpolate bad channels before re-referencing to average reference #\n",
    "\n",
    "1. Get a first general idea of \"bad\" channels using automatic classification\n",
    "2. Plot data and scroll through the full recording session: check channels flagged in the automatic detection method, and if necessary delete other bad-looking channels \n",
    "3. Interpolate channels labeled as bad\n",
    "4. Re-reference to average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c207f4",
   "metadata": {},
   "source": [
    "## 3.1. Recognising bad channels by Z-scoring and looking at SD and variance in freq. and time domain ##\n",
    "\n",
    "**PSD_Z:**\n",
    "- Computes each channel’s average power (1–80 Hz) in dB, then z-scores across channels—so it flags electrodes whose overall spectral “bulk” is unusually high or low (e.g., a consistently noisy or dead contact) (A single value per channel, tells us whether the channel is generally noisier or quieter than the others) (looks at Frequency domain).\n",
    "\n",
    "**P2P_Z:**\n",
    "- Measures the maximum 250 ms peak-to-peak excursion per channel and z-scores those values—so it catches electrodes with extreme transients (cable pops, big spikes) or abnormally flat signals (looks at Time domain)\n",
    "(Takes the highest voltage the channel reaches minus the lowest voltage it reaches—that difference is its peak-to-peak value.)\n",
    "\n",
    "**Corr_Z:**\n",
    "- Computes each channel’s mean Pearson correlation to all other channels, then z-scores—so it flags sensors that aren’t co-varying with the head (e.g., drifty or disconnected channels, channels that don't correlate with their neighbours).\n",
    "\n",
    "**Var_Z:**\n",
    "- Takes each channel’s overall variance and z-scores—so it highlights electrodes that are unusually “spiky” or “quiet” over the whole recording (looks at Time domain).\n",
    "\n",
    "**Max_Freq_Z:**\n",
    "- Looks for the largest per-frequency deviation (in z-units) from the grand mean spectrum—so it catches narrowband bursts (line-noise leakage, muscle peaks) that might be lost in the broad PSD average (=For each frequency bin look at how many SD above/below the across-channel mean power that channel’s power is at that exact frequency (i.e. a z-score at 10 Hz, at 20 Hz, etc.), and take whichever of those frequency-specific z-scores is largest in absolute value. That way, even if a channel’s overall PSD looks okay, a single narrowband spike (say a 50 Hz line-noise leak or a muscle peak at 80 Hz) will make its “max_freq_z” jump out.) (looks at Frequency domain).\n",
    "\n",
    "#### Rule of thumb:\n",
    "- If it fails two or more of the checks, probably bad - but do a visual check of PSD and raw trace\n",
    "- Failing one check: Look at PSD and raw trace - if looking good, keep it in\n",
    "\n",
    "**NOTE** Frontal channels can often be flagged, but that is likely because of eyeblinks, so don't necessarily remove them if the raw trace itself looks ok besides the eyeblink!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d943670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# rename for readability\n",
    "bad_chan_identifier = filt_eeg_data.copy().drop_channels(['Fp1', 'Fpz', 'Fp2']) # drop frontal channels because they are often noisy due to eye blinks and this affects the mean/variance computed\n",
    "\n",
    "# pick only the EEG channels that aren’t already in raw.info['bads']\n",
    "picks = mne.pick_types(bad_chan_identifier.info, meg=False, eeg=True, exclude='bads')\n",
    "\n",
    "sfreq = bad_chan_identifier.info['sfreq']\n",
    "\n",
    "# Frequency-domain PSD checks\n",
    "psd_container = bad_chan_identifier.compute_psd(\n",
    "    method=\"welch\",\n",
    "    picks=picks,\n",
    "    fmin=1.0,\n",
    "    fmax=80.0,\n",
    "    n_fft=160,\n",
    "    window=\"hamming\"\n",
    ")\n",
    "\n",
    "# Convert to dB and compute mean PSD per channel\n",
    "psds     = psd_container.get_data()     # (n_picks, n_freqs)\n",
    "psd_db   = 10 * np.log10(psds)\n",
    "mean_psd = psd_db.mean(axis=1)\n",
    "psd_z    = (mean_psd - mean_psd.mean()) / mean_psd.std()\n",
    "\n",
    "# Peak-to-peak amplitude in 250 ms windows\n",
    "data = bad_chan_identifier.get_data(picks=picks)     # (n_picks, n_times)\n",
    "win_samp = int(0.25 * sfreq)\n",
    "n_win    = data.shape[1] // win_samp\n",
    "p2p_mat  = np.zeros((len(picks), n_win))\n",
    "for w in range(n_win):\n",
    "    seg = data[:, w*win_samp:(w+1)*win_samp]\n",
    "    p2p_mat[:, w] = seg.max(axis=1) - seg.min(axis=1)\n",
    "max_p2p = p2p_mat.max(axis=1)\n",
    "p2p_z   = (max_p2p - max_p2p.mean()) / max_p2p.std()\n",
    "\n",
    "# Channel–channel correlation \n",
    "corr      = np.corrcoef(data)\n",
    "mean_corr = corr.mean(axis=0)\n",
    "corr_z    = (mean_corr - mean_corr.mean()) / mean_corr.std()\n",
    "\n",
    "# Compute time-domain variance per channel and z-score\n",
    "# Flags channels with too much or too little amplitude variability over the rec (relative to the other electrodes),\n",
    "# i.e., it could be flat or very spiky\n",
    "chan_vars = np.var(data, axis=1)\n",
    "var_z     = (chan_vars - chan_vars.mean()) / chan_vars.std()\n",
    "\n",
    "# Compute frequency-wise z-scores and max deviation per channel\n",
    "# Looks for channels which have high spikes in some frequencies, could indicate e.g., line noise or muscle artefact\n",
    "mean_freq   = psd_db.mean(axis=0)\n",
    "std_freq    = psd_db.std(axis=0)\n",
    "freq_z      = (psd_db - mean_freq) / std_freq\n",
    "max_freq_z  = np.max(np.abs(freq_z), axis=1)\n",
    "\n",
    "# Threshold all metrics at ±2.5 Z\n",
    "thresh = 2.5\n",
    "mask_psd   = np.abs(psd_z)    > thresh\n",
    "mask_p2p   = np.abs(p2p_z)    > thresh\n",
    "mask_corr  = corr_z           < -thresh    # flag very low corr (z < -2.5)\n",
    "mask_var   = np.abs(var_z)    > thresh\n",
    "mask_freq  = max_freq_z       > thresh\n",
    "\n",
    "# combine\n",
    "mask_all = mask_psd | mask_p2p | mask_corr | mask_var | mask_freq\n",
    "bad_channels = [bad_chan_identifier.ch_names[picks[i]]\n",
    "                for i, m in enumerate(mask_all) if m]\n",
    "\n",
    "# Print per-metric flagged channels\n",
    "print(\">> PSD outliers (|z|>2.5):\", [bad_chan_identifier.ch_names[picks[i]] for i in np.where(mask_psd)[0]])\n",
    "print(\">> Peak-to-peak outliers (|z|>2.5):\", [bad_chan_identifier.ch_names[picks[i]] for i in np.where(mask_p2p)[0]])\n",
    "print(\">> Low-correlation outliers (corr_z < -2.5):\", [bad_chan_identifier.ch_names[picks[i]] for i in np.where(mask_corr)[0]])\n",
    "print(\">> Variance outliers (|z|>2.5):\", [bad_chan_identifier.ch_names[picks[i]] for i in np.where(mask_var)[0]])\n",
    "print(\">> Spectral‐spike outliers (max_freq_z>2.5):\", [bad_chan_identifier.ch_names[picks[i]] for i in np.where(mask_freq)[0]])\n",
    "print(\">> Final flagged channels:\", bad_channels)\n",
    "\n",
    "# Summarize in a DataFrame \n",
    "df = pd.DataFrame({\n",
    "    \"Channel\":     [bad_chan_identifier.ch_names[p]      for p in picks],\n",
    "    \"PSD_Z\":       np.round(psd_z,    2),\n",
    "    \"P2P_Z\":       np.round(p2p_z,    2),\n",
    "    \"Corr_Z\":      np.round(corr_z,   2),\n",
    "    \"Var_Z\":       np.round(var_z,    2),\n",
    "    \"Max_Freq_Z\":  np.round(max_freq_z,2),\n",
    "    \"Flagged\":     mask_all\n",
    "})\n",
    "print(df)\n",
    "\n",
    "# Visual check: all individual PSDs\n",
    "bad_chan_identifier.plot_psd(\n",
    "    fmin=1.0, fmax=80.0,\n",
    "    picks=picks,\n",
    "    dB=True,\n",
    "    average=False,\n",
    "    show=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04e815b",
   "metadata": {},
   "source": [
    "## 3.2. Scrolling through recording and manual removal of \"bad\" channels ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de6ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# Plot raw signal\n",
    "filt_eeg_data.plot(n_channels = len(ch_names), duration = 20, scalings=\"auto\", block=True) # Cell block waits for plot to be closed before continuing (i.e., saving)\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "file_p = join(save_path, f\"{sub.replace(' ', '_')}_artefacts_removed_EEGdata_eeg.fif\")\n",
    "filt_eeg_data.save(file_p, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f12381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure bad channels are listed here, otherwise they will be included in the average reference\n",
    "filt_eeg_data.info['bads']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf98e97",
   "metadata": {},
   "source": [
    "## 3.3. Interpolate bad channels ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d9dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data_interp = filt_eeg_data.copy().interpolate_bads(reset_bads=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5897f691",
   "metadata": {},
   "source": [
    "## 3.4. Re-reference to average ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0743bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_ref_data = []\n",
    "av_ref_data = eeg_data_interp.copy().set_eeg_reference(ref_channels=\"average\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5211b1db",
   "metadata": {},
   "source": [
    "#### Plot PSD again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc1875",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "### Plot PSD of signal (averaging all channels)\n",
    "psd_final_avg = av_ref_data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=1, fmax=130, window=\"hamming\")\n",
    "psd_final_avg.plot(dB=True, average=True).suptitle(f\"{sub} PSD after re-referencing\")\n",
    "plt.show()\n",
    "\n",
    "### Plot PSD of signal (not averaging)\n",
    "psd_final = av_ref_data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=1, fmax=130, window=\"hamming\")\n",
    "psd_final.plot(dB=True, average=False).suptitle(f\"{sub} PSD after re-referencing\")\n",
    "plt.savefig(join(sub_save_path, f\"{sub}_after_reRef.png\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ceed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "av_ref_data.plot(n_channels = len(ch_names), scalings=\"auto\", title=\"After re-referencing to average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab0b03e",
   "metadata": {},
   "source": [
    "# 4. Clean artifatcs using Independent Component Analysis #\n",
    "\n",
    "1. Fit ICA to the filtered re-referenced data\n",
    "2. Automatic labelling of \"bad\" components\n",
    "    1. Using mne-icalabel\n",
    "    2. Using eegprep (from Arnaud Delorme)\n",
    "3. Manual labelling of \"bad\" components (and comparison with automatic)\n",
    "4. Select which ICA components to exclude and reconstruct the signal without them\n",
    "\n",
    "\n",
    "**Notes from https://eeglab.org/tutorials/06_RejectArtifacts/RunICA.html:**\n",
    "\n",
    "\"ICA takes all training data into consideration. When too many types (i.e., scalp distributions) of noise - complex movement artifacts, electrode pops, etc – are left in the training data, these unique and irreplicable data features will draw the attention of ICA, producing a set of component maps including many single-channel or noisy-appearing components. The number of components (degrees of freedom) devoted to the decomposition of brain EEG alone will be correspondingly reduced.\n",
    "Therefore, presenting ICA with as much clean EEG data as possible is the best strategy. Note that blink and other stereotyped EEG artifacts do not necessarily have to be removed since they are likely to be isolated as single ICA components.\n",
    "Here clean EEG data means data after removing noisy time segments (does not apply to removed ICA components).\" --> hence, remove breaks before runnning ICA\n",
    "\n",
    "**Random note:**\n",
    "\n",
    "When cognitive load increases, blinking usually decreases. Because when participants are expecting something important to happen (stimulus appearance), they will unconsciously try not to blink, to pay more attention (source: https://www.youtube.com/watch?v=AXCxrDikpaM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d53616",
   "metadata": {},
   "source": [
    "## 4.1. Fit the ICA ##\n",
    "\n",
    "Here we use the extended infomax method, because it is the preferred method for mne-icalabel automatic classification. The ICA must be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dec8166",
   "metadata": {},
   "outputs": [],
   "source": [
    "break_annot = mne.preprocessing.annotate_break(av_ref_data, min_break_duration=10, t_start_after_previous=4, t_stop_before_next=4)\n",
    "### Add the breaks to the annotations of the data\n",
    "av_ref_data2 = av_ref_data.set_annotations(raw.annotations + break_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4d405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the fitted or loaded ICA objects\n",
    "ica_fit_dict = {}\n",
    " \n",
    "# Construct the file path for the ICA file\n",
    "ica_file_path = join(saving_path, 'sub_data', f\"{sub}\", f\"{sub}-ica.fif\")\n",
    "    \n",
    "# # Check if the ICA file exists\n",
    "# if os.path.exists(ica_file_path):\n",
    "#     # If it exists, load the ICA object\n",
    "#     ica = read_ica(ica_file_path)\n",
    "#     print(f\"Loaded ICA for {sub} from {ica_file_path}\")\n",
    "\n",
    "# else:\n",
    "# If it doesn't exist, fit ICA to the data\n",
    "ica = ICA(n_components=None, random_state=11, method='infomax', fit_params=dict(extended=True)) # Number of components is chosen by function to account for 99%\n",
    "ica.fit(av_ref_data2.copy().pick_types(eeg=True), reject_by_annotation=True)                                  \n",
    "\n",
    "# Save the ICA object to file (saving the ICA decomposition, not any raw/cleaned data)\n",
    "ica.save(ica_file_path, overwrite=True)\n",
    "print(f\"Fitted and saved ICA for {sub} at {ica_file_path}\")\n",
    "    \n",
    "ica_fit_dict = ica\n",
    "\n",
    "# for i in range(ica.n_components_):\n",
    "#     fig = ica_fit_dict.plot_properties(picks=[i], inst=av_ref_data2, show=False) #Topographies of each component\n",
    "#     plt.savefig(join(sub_save_path, f\"{sub}_ica_component_{i}.png\"), dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952f6925",
   "metadata": {},
   "source": [
    "## 4.2. Automatic labelling of \"bad\" components ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760c7764",
   "metadata": {},
   "source": [
    "### 4.2.1. Using mne-icalabel ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb21b15d",
   "metadata": {},
   "source": [
    "Trying automatic labeling using mne-icalabel package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Get automatic classification labels for ICA components using mne-icalabel package (pip install mne-icalabel) to get a first idea\n",
    "ic_labels = label_components(av_ref_data, ica, method=\"iclabel\")\n",
    "labels = ic_labels[\"labels\"]\n",
    "mne_icalabel_excluded = [\n",
    "    idx for idx, label in enumerate(labels) if label not in [\"brain\", \"other\"]\n",
    "]\n",
    "mne_icalabel_labels = [\n",
    "    (idx, label) for idx, label in enumerate(labels)\n",
    "]\n",
    "print(f\"Excluding these ICA components: {mne_icalabel_excluded}\")\n",
    "\n",
    "ica.plot_properties(av_ref_data, picks=mne_icalabel_excluded, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f546a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_icalabel_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68543793",
   "metadata": {},
   "source": [
    "### 4.2.2. Using eegprep (from Arnaud Delorme) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033001d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from eegprep import iclabel\n",
    "# EEG = iclabel(av_ref_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f8b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## HERE ADD EEGPREP PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae8770d",
   "metadata": {},
   "source": [
    "## 4.3. Manual labelling of \"bad' ICA components ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2684bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig_sources = ica.plot_sources(av_ref_data2) # Timeseries of each ICA component\n",
    "plt.savefig(join(sub_save_path, f\"{sub}_ica_sources.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e632843",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "fig = ica.plot_components(inst=av_ref_data,  psd_args={'fmin': 0, 'fmax': 80}, ncols=6, nrows=6) #Topographies of each component\n",
    "plt.savefig(join(sub_save_path, f\"{sub}_ica_components.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa635f2",
   "metadata": {},
   "source": [
    "## 4.4. Select final components to exclude and reconstruct signal ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_exclude = [0, 1, 9, 10, 11, 12, 13, 17, 21, 22, 23]\n",
    "to_exclude = mne_icalabel_excluded.copy()\n",
    "to_exclude.append(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da190ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec759a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.exclude = to_exclude\n",
    "ica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3af4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply ICA to the data\n",
    "data_after_ica = ica.apply(av_ref_data2.copy(), exclude=to_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265a64b",
   "metadata": {},
   "source": [
    "# 5. Visual inspection and saving after all preprocessing steps and ICA #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feda663",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "data_after_ica.plot(n_channels=len(ch_names), scalings=\"auto\", title=\"After ICA\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "### Plot PSD of signal (not averaging)\n",
    "psd_after_ica = data_after_ica.compute_psd(method=\"welch\", picks=\"eeg\", fmin=1, fmax=80, window=\"hamming\")\n",
    "psd_after_ica.plot(dB=True, average=False).suptitle(f\"{sub} PSD after ICA\")\n",
    "sub_save_path = join(saving_path, \"sub_data\", f\"{sub}\", \"figures\", \"PSDs\")\n",
    "plt.savefig(join(sub_save_path, f\"{sub}_after_ICA_PSD.png\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f973b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(saving_path, \"sub_data\", f\"{sub}\", \"data\")\n",
    "os.makedirs(save_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "file_p = join(save_path, f\"{sub.replace(' ', '_')}_postICA_EEGdata_eeg.fif\")\n",
    "data_after_ica.save(file_p, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda58920",
   "metadata": {},
   "source": [
    "# 6. ADDITIONAL: Extract epochs to check data quality after ICA and plot specific channels: \n",
    "C3/C4 channels are the ones above the motor cortex, they can be plotted to check that the expected beta desynchronization is visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80588fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "events, event_dict = mne.events_from_annotations(data_after_ica)\n",
    "# List of keys to keep\n",
    "keys_to_keep = ['GC', 'GF', 'GO', 'GS', 'continue', 'stop']\n",
    "\n",
    "# Create the new dictionary by filtering the original one\n",
    "filtered_event_dict = {key: event_dict[key] for key in keys_to_keep}\n",
    "\n",
    "print(filtered_event_dict)\n",
    "# Get the event codes (values) from the filtered dictionary\n",
    "valid_event_codes = list(filtered_event_dict.values())\n",
    "\n",
    "# Filter the events array where the event code is in the valid_event_codes list\n",
    "filtered_events = np.array([event for event in events if event[2] in valid_event_codes])\n",
    "\n",
    "print(filtered_events)\n",
    "#picks = [raw.ch_names[0], raw.ch_names[1]]\n",
    "tmin = -3.5\n",
    "tmax = 3.5\n",
    "epochs = mne.Epochs(data_after_ica, filtered_events, event_id=filtered_event_dict, tmin=tmin, tmax=tmax, baseline=(None, 0), preload=True)\n",
    "metadata = pd.DataFrame({'subject':[sub] * len(epochs)})\n",
    "epochs.metadata = metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f0d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs['GO'].average().plot(xlim=(-0.5, 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57bda4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e919a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# Generate list of evoked objects from conditions names\n",
    "evokeds = [epochs[name].average() for name in (\"GO\", \"GF\",\"GC\", \"GS\")]\n",
    "colors = \"blue\", \"red\", \"green\", \"black\"\n",
    "title = \"Evoked responses\"\n",
    "\n",
    "fig, axes = plt.subplots(1)\n",
    "\n",
    "mne.viz.plot_evoked_topo(evokeds, title=title, background_color=\"w\", axes=axes)\n",
    "\n",
    "fig.savefig(join(saving_path, 'evoked_responses.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5260f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = io.load_behav_data([session_id], onedrive_path)\n",
    "\n",
    "stats = {}\n",
    "stats = utils.extract_stats(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553de7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare variables and dictionaries for storing results\n",
    "# Dictionary to store subject epochs in\n",
    "sub_dict_epochs_subsets = {}  #  Stores the epochs for each condition and for each subject/session\n",
    "sub_dict_lm_GO = {}  #  Stores the epochs for lm_GO trials for each subject/session\n",
    "sub_dict_RT = {}  #  Stores the mean reaction time for each trial type\n",
    "sub_dict_stats = {}  #  Stores behavioral stats for each subject/session\n",
    "\n",
    "cluster_results_dict = {}\n",
    "cluster_results_dict = defaultdict(dict)  # Each missing key gets an empty dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7699a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_dict = {}\n",
    "sub = session_id[:6]\n",
    "subject_ID = session_id.split(' ') [0]\n",
    "condition = session_id.split(' ') [1] + ' ' + session_id.split(' ') [2]\n",
    "sub_onedrive_path = join(onedrive_path, subject_ID)\n",
    "sub_onedrive_path_task = join(onedrive_path, subject_ID, 'synced_data', session_id)\n",
    "\n",
    "saving_path_single = join(results_path, 'single_sub', f'{sub} mSST','eeg') \n",
    "os.makedirs(saving_path_single, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "epochs, filtered_event_dict = preprocessing.create_epochs(data_after_ica, session_id)\n",
    "\n",
    "mSST_raw_behav_session_data_path = join(\n",
    "        onedrive_path, subject_ID, \"raw_data\", 'BEHAVIOR', condition, 'mSST'\n",
    "        )\n",
    "for filename in os.listdir(mSST_raw_behav_session_data_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            fname = filename\n",
    "filepath_behav = join(mSST_raw_behav_session_data_path, fname)\n",
    "df = pd.read_csv(filepath_behav)\n",
    "\n",
    "# return the index of the first row which is not filled by a Nan value:\n",
    "start_task_index = df['blocks.thisRepN'].first_valid_index()\n",
    "# Crop dataframe in 2 parts: before and after the task:\n",
    "df_maintask = df.iloc[start_task_index:-1]\n",
    "\n",
    "# remove the trials with early presses, as in these trials the cues were not presented\n",
    "early_presses = df_maintask[df_maintask['early_press_resp.corr'] == 1]\n",
    "early_presses_trials = list(early_presses.index)\n",
    "number_early_presses = len(early_presses_trials)\n",
    "\n",
    "# remove trials with early presses from the dataframe:\n",
    "df_maintask_copy = df_maintask.drop(early_presses_trials)\n",
    "\n",
    "# Filter successful and unsuccessful trials:\n",
    "(epochs_subsets, epochs_lm, mean_RT_dict) = preprocessing.create_epochs_subsets_from_behav(\n",
    "        df_maintask_copy, \n",
    "        epochs, \n",
    "        filtered_event_dict\n",
    "        )\n",
    "\n",
    "sub_dict_epochs_subsets[session_id] = epochs_subsets\n",
    "sub_dict_lm_GO[session_id] = epochs_lm\n",
    "sub_dict_RT[session_id] = mean_RT_dict\n",
    "sub_dict_stats[session_id] = stats[session_id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecba114",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "### TFR PARAMETERS ###\n",
    "######################\n",
    "\n",
    "decim = 1 \n",
    "freqs = np.arange(1, 80, 1) \n",
    "# For 500ms time resolution at 1 Hz: n_cycles = 1 * 0.5 = 0.5\n",
    "# For 50ms time resolution at 40 Hz: n_cycles = 40 * 0.05 = 2\n",
    "# Linear interpolation between these points\n",
    "#n_cycles = 0.5 + (freqs - 1) * (2 - 0.5) / (40 - 1)\n",
    "#n_cycles = freqs / 2.0\n",
    "n_cycles = np.minimum(np.maximum(freqs / 2.0, 2), 10)\n",
    "\n",
    "tfr_args = dict(\n",
    "    method=\"morlet\",\n",
    "    freqs=freqs,\n",
    "    n_cycles=n_cycles,\n",
    "    decim=decim,\n",
    "    return_itc=False,\n",
    "    average=False\n",
    ")        \n",
    "\n",
    "tmin_tmax = [-500, 1500]\n",
    "vmin_vmax = [-70, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd8fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sub_dict_subsets = {key: value for key, value in sub_dict_epochs_subsets.items() if sub in key}\n",
    "print(single_sub_dict_subsets.keys())\n",
    "single_sub_dict_lm_GO = {key: value for key, value in sub_dict_lm_GO.items() if sub in key}\n",
    "single_sub_RT_dict = {key: value for key, value in sub_dict_RT.items() if sub in key}\n",
    "single_sub_stats_dict = {key: value for key, value in sub_dict_stats.items() if sub in key}\n",
    "saving_path_single = join(results_path, 'single_sub', f'{sub} mSST','lfp_perc_sig_change', 'beta_only')\n",
    "os.makedirs(saving_path_single, exist_ok=True)  # Create the directory if it doesn't exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0ed487",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "epochs_subsets.plot(n_channels = 32, n_epochs = 4, events=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ca5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ch_interest = \"Cz\"\n",
    "epoch_cond = 'GO_successful'\n",
    "t_min_max = [-500, 1500]\n",
    "data = epochs_subsets[epoch_cond]\n",
    "C4_epochs = data.copy().pick([ch_interest])\n",
    "power_c4 = C4_epochs.compute_tfr(**tfr_args)\n",
    "mean_power_c4 = np.nanmean(power_c4.data, axis=0).squeeze()\n",
    "\n",
    "times = power_c4.times * 1000  # Convert to milliseconds\n",
    "freqs = power_c4.freqs\n",
    "\n",
    "baseline_indices = (times >= -500) & (times <= -200)\n",
    "baseline_power_c4 = np.nanmean(mean_power_c4[:, baseline_indices], axis=1, keepdims=True)\n",
    "percentage_change_c4 = (mean_power_c4 - baseline_power_c4) / baseline_power_c4 * 100\n",
    "\n",
    "time_indices = np.logical_and(times >= t_min_max[0], times <= t_min_max[1])\n",
    "sliced_data = percentage_change_c4[:, time_indices].squeeze()    \n",
    "\n",
    "plt.imshow(sliced_data, aspect='auto', origin='lower', \n",
    "        extent=[t_min_max[0], t_min_max[1], \n",
    "        tfr_args[\"freqs\"][0], tfr_args[\"freqs\"][-1]], \n",
    "        cmap='jet', vmin=vmin_vmax[0], vmax=vmin_vmax[-1]\n",
    ")\n",
    "plt.axvline(x=0, color='k', linestyle='--', linewidth=1)\n",
    "plt.title(f\"Percentage Change in Power for {epoch_cond} - {ch_interest}\")\n",
    "plt.xlabel(\"Time from GO cue (ms)\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.colorbar(label=\"Percentage Change (%)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908e3930",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_cond = 'GF_successful'\n",
    "t_min_max = [-500, 1500]\n",
    "data = epochs_subsets[epoch_cond]\n",
    "C4_epochs = data.copy().pick([ch_interest])\n",
    "power_c4 = C4_epochs.compute_tfr(**tfr_args)\n",
    "mean_power_c4 = np.nanmean(power_c4.data, axis=0).squeeze()\n",
    "\n",
    "times = power_c4.times * 1000  # Convert to milliseconds\n",
    "freqs = power_c4.freqs\n",
    "\n",
    "baseline_indices = (times >= -500) & (times <= -200)\n",
    "baseline_power_c4 = np.nanmean(mean_power_c4[:, baseline_indices], axis=1, keepdims=True)\n",
    "percentage_change_c4 = (mean_power_c4 - baseline_power_c4) / baseline_power_c4 * 100\n",
    "\n",
    "time_indices = np.logical_and(times >= t_min_max[0], times <= t_min_max[1])\n",
    "sliced_data = percentage_change_c4[:, time_indices].squeeze()    \n",
    "\n",
    "plt.imshow(sliced_data, aspect='auto', origin='lower', \n",
    "        extent=[t_min_max[0], t_min_max[1], \n",
    "        tfr_args[\"freqs\"][0], tfr_args[\"freqs\"][-1]], \n",
    "        cmap='jet', vmin=vmin_vmax[0], vmax=vmin_vmax[-1]\n",
    ")\n",
    "plt.axvline(x=0, color='k', linestyle='--', linewidth=1)\n",
    "plt.title(f\"Percentage Change in Power for {epoch_cond} - {ch_interest}\")\n",
    "plt.xlabel(\"Time from GO cue (ms)\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.colorbar(label=\"Percentage Change (%)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bbf88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_cond = 'GS_successful'\n",
    "t_min_max = [-500, 1500]\n",
    "data = epochs_subsets[epoch_cond]\n",
    "fz_epochs = data.copy().pick([ch_interest])\n",
    "power_fz = fz_epochs.compute_tfr(**tfr_args)\n",
    "mean_power_fz = np.nanmean(power_fz.data, axis=0).squeeze()\n",
    "\n",
    "times = power_fz.times * 1000  # Convert to milliseconds\n",
    "freqs = power_fz.freqs\n",
    "\n",
    "baseline_indices = (times >= -500) & (times <= -200)\n",
    "baseline_power_fz = np.nanmean(mean_power_fz[:, baseline_indices], axis=1, keepdims=True)\n",
    "percentage_change_fz = (mean_power_fz - baseline_power_fz) / baseline_power_fz * 100\n",
    "\n",
    "time_indices = np.logical_and(times >= t_min_max[0], times <= t_min_max[1])\n",
    "sliced_data_fz = percentage_change_fz[:, time_indices].squeeze()    \n",
    "\n",
    "plt.imshow(sliced_data_fz, aspect='auto', origin='lower', \n",
    "        extent=[t_min_max[0], t_min_max[1], \n",
    "        tfr_args[\"freqs\"][0], tfr_args[\"freqs\"][-1]], \n",
    "        cmap='jet', vmin=vmin_vmax[0], vmax=vmin_vmax[-1]\n",
    ")\n",
    "plt.axvline(x=0, color='k', linestyle='--', linewidth=1)\n",
    "plt.title(f\"Percentage Change in Power for {epoch_cond} - {ch_interest}\")\n",
    "plt.xlabel(\"Time from GO cue (ms)\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.colorbar(label=\"Percentage Change (%)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23b9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_cond = 'GS_unsuccessful'\n",
    "t_min_max = [-500, 1500]\n",
    "data = epochs_subsets[epoch_cond]\n",
    "fz_epochs = data.copy().pick([ch_interest])\n",
    "power_fz = fz_epochs.compute_tfr(**tfr_args)\n",
    "mean_power_fz = np.nanmean(power_fz.data, axis=0).squeeze()\n",
    "\n",
    "times = power_fz.times * 1000  # Convert to milliseconds\n",
    "freqs = power_fz.freqs\n",
    "\n",
    "baseline_indices = (times >= -500) & (times <= -200)\n",
    "baseline_power_fz = np.nanmean(mean_power_fz[:, baseline_indices], axis=1, keepdims=True)\n",
    "percentage_change_fz = (mean_power_fz - baseline_power_fz) / baseline_power_fz * 100\n",
    "\n",
    "time_indices = np.logical_and(times >= t_min_max[0], times <= t_min_max[1])\n",
    "sliced_data_fz = percentage_change_fz[:, time_indices].squeeze()    \n",
    "\n",
    "plt.imshow(sliced_data_fz, aspect='auto', origin='lower', \n",
    "        extent=[t_min_max[0], t_min_max[1], \n",
    "        tfr_args[\"freqs\"][0], tfr_args[\"freqs\"][-1]], \n",
    "        cmap='jet', vmin=vmin_vmax[0], vmax=vmin_vmax[-1]\n",
    ")\n",
    "plt.axvline(x=0, color='k', linestyle='--', linewidth=1)\n",
    "plt.title(f\"Percentage Change in Power for {epoch_cond} - {ch_interest}\")\n",
    "plt.xlabel(\"Time from GO cue (ms)\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.colorbar(label=\"Percentage Change (%)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7205da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f985ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# Generate list of evoked objects from conditions names\n",
    "evokeds_stopping = [epochs_subsets[name].average() for name in (\"GS_successful\", \"GS_unsuccessful\")]\n",
    "colors = \"green\", \"red\"\n",
    "title = \"Evoked stopping responses\"\n",
    "\n",
    "fig, axes = plt.subplots(1)\n",
    "\n",
    "mne.viz.plot_evoked_topo(evokeds_stopping, title=title, background_color=\"w\", axes=axes)\n",
    "\n",
    "#fig.savefig(join(saving_path, 'evoked_GS_success_unsuccess_responses.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c1156",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# Generate list of evoked objects from conditions names\n",
    "evokeds = [epochs_subsets[name].average() for name in (\"GO_successful\", \"GS_successful\")]\n",
    "colors = (\"green\", 0.5), (\"red\", 0.5)\n",
    "title = \"Evoked reactive inhibition responses compared to going\"\n",
    "\n",
    "fig, axes = plt.subplots(1)\n",
    "\n",
    "mne.viz.plot_evoked_topo(evokeds, color=colors,title=title, background_color=\"w\", axes=axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c2bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# Generate list of evoked objects from conditions names\n",
    "evokeds = [epochs_subsets[name].average() for name in (\"GO_successful\", \"GF_successful\")]\n",
    "colors = (\"green\", 0.5), (\"blue\", 0.5)\n",
    "title = \"Evoked proactive inhibition responses\"\n",
    "\n",
    "fig, axes = plt.subplots(1)\n",
    "\n",
    "mne.viz.plot_evoked_topo(evokeds, color=colors,title=title, background_color=\"w\", axes=axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ab604b",
   "metadata": {},
   "source": [
    "### Note\n",
    "Once each subject has been preprocessed and epochs cleaned, other scripts will load the cleaned epochs and run the analyses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ephy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
