{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f4d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT EXTERNAL FUNCTIONS\n",
    "import mne\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.preprocessing import ICA, read_ica\n",
    "from collections import defaultdict\n",
    "\n",
    "os.getcwd()\n",
    "import functions.io as io\n",
    "import functions.utils as utils\n",
    "import functions.preprocessing as preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c39c618",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "- Loads data (single sub)\n",
    "- Checks unit of raw data (without any manipulation of raw, just checking)\n",
    "- Dropping channels that aren't of interest, and setting channel types (you will want to keep X.Y,Z channels though!)\n",
    "- Re-scales data and replaces raw (if check above suggests that data is in \"raw units ADC\" from amplifier. If one needs to be rescaled all do, but I keep the check in here just so I/we know what's going on and why we're rescaling)\n",
    "- Set montage (so that each electrode has it's location when we use scalp tophographies for visualisations and electrode placement (and later for other stuff I assume))\n",
    "- High- and low-pass filter + notch filter\n",
    "- Annotate breaks, so that beginning, breaks between blocks, and end isn't included in the analyses. I found that if we crop the event timings get shifted, if we just annotate here then we don't shift any times and events around, and the \"bad\" parts are not included in analyses.\n",
    "- Plot raw trace and manually annotate bad parts of raw trace (I think only the most obvious movements/artefacts with huge shifts amplitude). Annotating can be done when seeing raw traces interactivately, click \"a\" on keybord to get the \"helper/info\" and then type \"movement\" straight away and hit enter. This creates a new \"marker\" which you then use to mark bad segments (click and drag over the bad segments). Also remove obviously bad channels here (more info at that stage).\n",
    "- Following this, when the obviously bad movements/artefacts/channels are removed, we can run some checks on channels to check if they are likely to be bad or not - see more info at that point in the notebook. I still don't know what's \"appropriate\" to do here, but the code is there if useful, and if the results can be used to guide selection of channels?\n",
    "- After all removal -> re-reference to average\n",
    "- Run ICA and save it so I don't need to re-run it later (if everything is identical in preprocessing), but can load it and apply it to the data again with e.g., other components removed etc. \n",
    "- Plot ICA components to see topographies, time series of components, how much variance is explained by the components etc (I don't really understand this variance fully, what is good and what is bad? Is there a good and bad?). Then some mne functions that \"automatically\" suggests which components are likely to be ECG, EOG, and mostly muscle noise. I think for now i prefer to do it manually, and use these checks as guides and compare to what I think the components are - see more notes at that point in the notebook.\n",
    "- Select bad components and remove them \n",
    "- Apply the ICA to data\n",
    "- After this the preprocessing of raw data is done. \n",
    "\n",
    "\n",
    "I then have parts where I epoch the data, and then remove bad epochs (the parts I have previously marked as bad are still in the data, because when I load the epochs I tell it to also include what segments of the raw trace I marked as bad to be excluded. I found that if I exclude the \"bad_movement\" I marked manually before ICA, all my epoch indexes are shifted because parts of the data has been removed, so the behavioural file index and actual remaining data indexes are not matching and I'm pulling the wrong epochs in my extract epoch functions. By keeping the \"bad_movement\" data in when I extract epochs, no data is removed when epochs are created, so I will have to quickly go over and just remove those that are bad again). This could probably be done in a smoother way, but I don't find this too annyoing to do, at epoch level it doesn't take too long to quickly scan through. \n",
    "\n",
    "\n",
    "I plot (and save) PSDs regularly to see what the impact the different preprocessing steps have. Might not be necessary later on - but for now i find it ok. \n",
    "I also save the file after some steps (it is marked when saved), so that the steps that takes long/are tedious don't have to be re-done all the time if wanting to test different methods etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00371ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session to preprocess\n",
    "session_id = \"sub006 DBS OFF mSST\"\n",
    "\n",
    "working_path = os.path.dirname(os.getcwd())\n",
    "onedrive_path = utils._get_onedrive_path()\n",
    "\n",
    "sub = session_id.split(' ') [0]\n",
    "condition = session_id.split(' ') [1] + ' ' + session_id.split(' ') [2]\n",
    "sub_onedrive_path_task = join(onedrive_path, sub, 'synced_data', session_id)\n",
    "\n",
    "#  Set saving path\n",
    "results_path = join(working_path, \"results\")\n",
    "saving_path = join(results_path, session_id)\n",
    "if not os.path.isdir(saving_path):\n",
    "    os.makedirs(saving_path)\n",
    "sub_save_path = join(saving_path, \"sub_data\", f\"{sub}\", \"figures\")\n",
    "os.makedirs(sub_save_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "save_path = os.path.join(saving_path, \"sub_data\", f\"{sub}\", \"data\")\n",
    "os.makedirs(save_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# Load raw data\n",
    "filename = [f for f in os.listdir(sub_onedrive_path_task) if (\n",
    "    f.endswith('.set') and f.startswith('SYNCHRONIZED_EXTERNAL'))]\n",
    "file = join(sub_onedrive_path_task, filename[0])\n",
    "raw = mne.io.read_raw(file, preload=True)\n",
    "\n",
    "# also load the two impedance files to check channels briefly\n",
    "impedance_folder = join(onedrive_path, sub, 'raw_data', 'XDF', condition)\n",
    "impedance_begin_filename = [f for f in os.listdir(impedance_folder) if (\n",
    "    f.endswith('.txt') and f.startswith('mSST_impedances_begin'))]\n",
    "impedance_end_filename = [f for f in os.listdir(impedance_folder) if (\n",
    "    f.endswith('.txt') and f.startswith('mSST_impedances_end'))]\n",
    "file_begin = join(impedance_folder, impedance_begin_filename[0])\n",
    "file_end = join(impedance_folder, impedance_end_filename[0])\n",
    "impedance_begin = pd.read_csv(file_begin, sep='\\t', header=None)\n",
    "impedance_end = pd.read_csv(file_end, sep='\\t', header=None)\n",
    "impedance_begin.drop(2, axis=1, inplace=True)  \n",
    "impedance_end.drop(2, axis=1, inplace=True)\n",
    "imp = impedance_begin.merge(impedance_end, on=0, how='outer', suffixes=('_begin', '_end'))\n",
    "# remove all rows starting with 'UNI':\n",
    "imp = imp[~imp[0].str.startswith('UNI')]\n",
    "\n",
    "# flag channels with impedance above 25 kOhm:\n",
    "high_imp_channels = imp[(imp['1_begin'] > 25) | (imp['1_end'] > 25)]\n",
    "if not high_imp_channels.empty:\n",
    "    print(\"Channels with high impedance (> 25 kOhm):\")\n",
    "    print(high_imp_channels)\n",
    "else:\n",
    "    print(\"No channels with high impedance found.\")\n",
    "\n",
    "sf = raw.info['sfreq']\n",
    "print(f\"Sampling frequency: {sf} Hz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d94398",
   "metadata": {},
   "source": [
    "#### Set channel types for BIP and drop useless extra channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.drop_channels(['CREF', 'X', 'Y', 'Z', 'TRIGGERS', 'STATUS', 'COUNTER', 'BIP 01'])\n",
    "raw.set_channel_types({'BIP 02': 'ecg', 'BIP 03': 'eog'}) \n",
    "\n",
    "# set 10-20 montage\n",
    "data = raw.set_montage('standard_1020', match_case=False, match_alias=True, on_missing='warn') \n",
    "ch_names = data.ch_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12473b7",
   "metadata": {},
   "source": [
    "#### Plot raw PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc91e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "### Plot PSD of signal (averaging all channels)\n",
    "psd_raw_avg = data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=0, fmax=130, n_fft=round(sf)*2, n_overlap=int(round(sf)), window=\"hamming\")\n",
    "psd_raw_avg.plot(dB=True, average=True).suptitle(f\"Raw PSD {sub}\")\n",
    "plt.show()\n",
    "\n",
    "### Plot PSD of signal (not averaging)\n",
    "psd_raw = data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=0, fmax=130, n_fft=round(sf)*2, n_overlap=int(round(sf)), window=\"hamming\")\n",
    "psd_raw.plot(dB=True, average=False).suptitle(f\"Raw PSD {sub}\")\n",
    "plt.savefig(join(sub_save_path, f\"{sub}_raw_PSD_avg.png\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a440b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "data.plot(n_channels = len(ch_names), scalings=\"auto\", title=\"Raw data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752322ae",
   "metadata": {},
   "source": [
    "### High- and low-pass filtering + notch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd67658",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_passed_filt_eeg_data = data.copy().filter(1, None) # first apply 1Hz high pass filter\n",
    "high_low_passed_filt_eeg_data = high_passed_filt_eeg_data.copy().filter(None, 80) # then apply 80Hz low pass filter\n",
    "# Plot filtered data\n",
    "high_low_passed_filt_eeg_data.plot(n_channels = len(ch_names), scalings=\"auto\", title=\"Filtered data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9cbea9",
   "metadata": {},
   "source": [
    "#### Plot PSD after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a6e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "### Plot PSD of signal (averaging all channels)\n",
    "psd_filt_avg = high_low_passed_filt_eeg_data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=0, fmax=100, n_fft=round(sf)*2, n_overlap=int(round(sf)), window=\"hamming\")\n",
    "psd_filt_avg.plot(dB=True, average=True).suptitle(f\"{sub} Filtered PSD\")\n",
    "plt.show()\n",
    "\n",
    "### Plot PSD of signal (not averaging)\n",
    "psd_filt = high_low_passed_filt_eeg_data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=0, fmax=100, n_fft=round(sf)*2, n_overlap=int(round(sf)), window=\"hamming\")\n",
    "psd_filt.plot(dB=True, average=False).suptitle(f\"{sub} Filtered PSD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0428d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually, even if 50Hz activity is not present here, it is sometimes present after re-referencing, so it is safer to apply a notch filter at 50Hz for all sessions\n",
    "filt_eeg_data = high_low_passed_filt_eeg_data.copy().notch_filter(50) \n",
    "\n",
    "# filt_eeg_data.notch_filter(48)  # for DBS ON: add a notch filter around other artifactual peaks (in our recordings, we commonly find a peak at 48Hz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b43afa",
   "metadata": {},
   "source": [
    "#### Annotating breaks\n",
    "Breaks are recognised by time without event markers.\n",
    "- Min_break_duration: How long time must be between event markers for this to be considered a break.\n",
    "- t_start_after_previous & t_start_before_next: How many seconds should be after the last event marker before the break starts, and how many seconds before the first event marker should the break stop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51667af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "break_annot = mne.preprocessing.annotate_break(filt_eeg_data, min_break_duration=10, t_start_after_previous=4, t_stop_before_next=4)\n",
    "### Add the breaks to the annotations of the data\n",
    "break_data = filt_eeg_data.set_annotations(raw.annotations + break_annot)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "# Plot signal (can check timeline on x-axis. The red blocks (break) should be where there are no event marker lines)\n",
    "filt_eeg_data.plot(n_channels = len(ch_names), scalings=\"auto\", title=\"Breaks added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795e2873",
   "metadata": {},
   "source": [
    "#### Plot PSD again - now breaks are not included in the PSD\n",
    "Depending on how much data has been excluded (i.e. how long the breaks were), and how much artefacts due to movement etc. were in the breaks, the PSD will look more or less like the PSD from before annotating breaks. \n",
    "\n",
    "However, it is good to remove breaks from the data when we re-reference to average - we don't want the break activity to influence the average signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518ea762",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "### Plot PSD of signal (averaging all channels)\n",
    "psd_noBreak_avg = filt_eeg_data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=0, fmax=130, window=\"hamming\")\n",
    "psd_noBreak_avg.plot(dB=True, average=True).suptitle(f\"{sub} PSD after annotating breaks\")\n",
    "plt.show()\n",
    "\n",
    "### Plot PSD of signal (not averaging)\n",
    "psd_noBreakfilt = filt_eeg_data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=0, fmax=130, window=\"hamming\")\n",
    "psd_noBreakfilt.plot(dB=True, average=False).suptitle(f\"{sub} PSD after annotating breaks\")\n",
    "sub_save_path = join(saving_path, \"sub_data\", f\"{sub}\", \"figures\", \"PSDs\")\n",
    "plt.savefig(join(sub_save_path, f\"{sub}_filtered_noBreak_PSD.png\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c309557a",
   "metadata": {},
   "source": [
    "#### Plot data and identify (select by clicking on them) bad channels\n",
    "Noisy channel identification can also be guided by the PSD above (plotting it interactively you can hover over the channels and get their names). Remove the ones which are clearly way below or above the main groupings of channels (but not frontal ones, they are likely eyeblinks in the lower frequencies). Don't be too strict in removing channels I think - the removing is still something I'm not sure how to best approach. We don't want to remove too much, because then ICA will be bad because we have removed all \"noise\", but we also want to remove channels that are clearly flat, or only noise. \n",
    "\n",
    "After artefact removal, the file is saved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca6fca4",
   "metadata": {},
   "source": [
    "JV: DO NOT ANNOTATE BAD SEGMENTS! Otherwise, there will be an error later on when trying to match epochs with behavioral data!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de6ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# Plot raw signal\n",
    "filt_eeg_data.plot(n_channels = len(ch_names), duration = 20, scalings=\"auto\", block=True) # Cell block waits for plot to be closed before continuing (i.e., saving)\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "file_p = join(save_path, f\"{sub.replace(' ', '_')}_artefacts_removed_EEGdata_eeg.fif\")\n",
    "filt_eeg_data.save(file_p, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096d19c",
   "metadata": {},
   "source": [
    "##### If already removed artefacts, load file from previous session so we don't need to repeat these steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d376dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_sub = sub.replace(' ', '_')\n",
    "# filename = join(saving_path, \"sub_data\", sub, \"data\", f\"{temp_sub}_artefacts_removed_EEGdata_eeg.fif\")\n",
    "\n",
    "# filt_eeg_break_data = mne.io.read_raw(filename, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c207f4",
   "metadata": {},
   "source": [
    "### Recognising bad channels by Z-scoring and looking at SD and variance in freq. and time domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8e69f5",
   "metadata": {},
   "source": [
    "**PSD_Z:**\n",
    "- Computes each channel’s average power (1–90 Hz) in dB, then z-scores across channels—so it flags electrodes whose overall spectral “bulk” is unusually high or low (e.g., a consistently noisy or dead contact) (A single value per channel, tells us whether the channel is generally noisier or quieter than the others) (looks at Frequency domain).\n",
    "\n",
    "**P2P_Z:**\n",
    "- Measures the maximum 250 ms peak-to-peak excursion per channel and z-scores those values—so it catches electrodes with extreme transients (cable pops, big spikes) or abnormally flat signals (looks at Time domain)\n",
    "(Takes the highest voltage the channel reaches minus the lowest voltage it reaches—that difference is its peak-to-peak value.)\n",
    "\n",
    "**Corr_Z:**\n",
    "- Computes each channel’s mean Pearson correlation to all other channels, then z-scores—so it flags sensors that aren’t co-varying with the head (e.g., drifty or disconnected channels, channels that don't correlate with their neighbours).\n",
    "\n",
    "**Var_Z:**\n",
    "- Takes each channel’s overall variance and z-scores—so it highlights electrodes that are unusually “spiky” or “quiet” over the whole recording (looks at Time domain).\n",
    "\n",
    "**Max_Freq_Z:**\n",
    "- Looks for the largest per-frequency deviation (in z-units) from the grand mean spectrum—so it catches narrowband bursts (line-noise leakage, muscle peaks) that might be lost in the broad PSD average (=For each frequency bin look at how many SD above/below the across-channel mean power that channel’s power is at that exact frequency (i.e. a z-score at 10 Hz, at 20 Hz, etc.), and take whichever of those frequency-specific z-scores is largest in absolute value. That way, even if a channel’s overall PSD looks okay, a single narrowband spike (say a 50 Hz line-noise leak or a muscle peak at 80 Hz) will make its “max_freq_z” jump out.) (looks at Frequency domain)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0faac6",
   "metadata": {},
   "source": [
    "#### Rule of thumb:\n",
    "- If it fails two or more of the checks, probably bad - but do a visual check of PSD and raw trace\n",
    "- Failing one check: Look at PSD and raw trace - if looking good, keep it in\n",
    "\n",
    "**NOTE** Frontal channels can often be flagged, but that is likely because of eyeblinks, so don't necessarily remove them if the raw trace itself looks ok besides the eyeblink!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d943670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# rename for readability\n",
    "bad_chan_identifier = filt_eeg_data\n",
    "\n",
    "# pick only the EEG channels that aren’t already in raw.info['bads']\n",
    "picks = mne.pick_types(bad_chan_identifier.info, meg=False, eeg=True, exclude='bads')\n",
    "\n",
    "sfreq = bad_chan_identifier.info['sfreq']\n",
    "\n",
    "# Frequency-domain PSD checks\n",
    "psd_container = bad_chan_identifier.compute_psd(\n",
    "    method=\"welch\",\n",
    "    picks=picks,\n",
    "    fmin=1.0,\n",
    "    fmax=80.0,\n",
    "    n_fft=160,\n",
    "    window=\"hamming\"\n",
    ")\n",
    "\n",
    "# Convert to dB and compute mean PSD per channel\n",
    "psds     = psd_container.get_data()     # (n_picks, n_freqs)\n",
    "psd_db   = 10 * np.log10(psds)\n",
    "mean_psd = psd_db.mean(axis=1)\n",
    "psd_z    = (mean_psd - mean_psd.mean()) / mean_psd.std()\n",
    "\n",
    "# Peak-to-peak amplitude in 250 ms windows\n",
    "data = bad_chan_identifier.get_data(picks=picks)     # (n_picks, n_times)\n",
    "win_samp = int(0.25 * sfreq)\n",
    "n_win    = data.shape[1] // win_samp\n",
    "p2p_mat  = np.zeros((len(picks), n_win))\n",
    "for w in range(n_win):\n",
    "    seg = data[:, w*win_samp:(w+1)*win_samp]\n",
    "    p2p_mat[:, w] = seg.max(axis=1) - seg.min(axis=1)\n",
    "max_p2p = p2p_mat.max(axis=1)\n",
    "p2p_z   = (max_p2p - max_p2p.mean()) / max_p2p.std()\n",
    "\n",
    "# Channel–channel correlation \n",
    "corr      = np.corrcoef(data)\n",
    "mean_corr = corr.mean(axis=0)\n",
    "corr_z    = (mean_corr - mean_corr.mean()) / mean_corr.std()\n",
    "\n",
    "# Compute time-domain variance per channel and z-score\n",
    "# Flags channels with too much or too little amplitude variability over the rec (relative to the other electrodes),\n",
    "# i.e., it could be flat or very spiky\n",
    "chan_vars = np.var(data, axis=1)\n",
    "var_z     = (chan_vars - chan_vars.mean()) / chan_vars.std()\n",
    "\n",
    "# Compute frequency-wise z-scores and max deviation per channel\n",
    "# Looks for channels which have high spikes in some frequencies, could indicate e.g., line noise or muscle artefact\n",
    "mean_freq   = psd_db.mean(axis=0)\n",
    "std_freq    = psd_db.std(axis=0)\n",
    "freq_z      = (psd_db - mean_freq) / std_freq\n",
    "max_freq_z  = np.max(np.abs(freq_z), axis=1)\n",
    "\n",
    "# Threshold all metrics at ±2.5 Z\n",
    "thresh = 2.5\n",
    "mask_psd   = np.abs(psd_z)    > thresh\n",
    "mask_p2p   = np.abs(p2p_z)    > thresh\n",
    "mask_corr  = corr_z           < -thresh    # flag very low corr (z < -2.5)\n",
    "mask_var   = np.abs(var_z)    > thresh\n",
    "mask_freq  = max_freq_z       > thresh\n",
    "\n",
    "# combine\n",
    "mask_all = mask_psd | mask_p2p | mask_corr | mask_var | mask_freq\n",
    "bad_channels = [bad_chan_identifier.ch_names[picks[i]]\n",
    "                for i, m in enumerate(mask_all) if m]\n",
    "\n",
    "# Print per-metric flagged channels\n",
    "print(\">> PSD outliers (|z|>2.5):\", [bad_chan_identifier.ch_names[picks[i]] for i in np.where(mask_psd)[0]])\n",
    "print(\">> Peak-to-peak outliers (|z|>2.5):\", [bad_chan_identifier.ch_names[picks[i]] for i in np.where(mask_p2p)[0]])\n",
    "print(\">> Low-correlation outliers (corr_z < -2.5):\", [bad_chan_identifier.ch_names[picks[i]] for i in np.where(mask_corr)[0]])\n",
    "print(\">> Variance outliers (|z|>2.5):\", [bad_chan_identifier.ch_names[picks[i]] for i in np.where(mask_var)[0]])\n",
    "print(\">> Spectral‐spike outliers (max_freq_z>2.5):\", [bad_chan_identifier.ch_names[picks[i]] for i in np.where(mask_freq)[0]])\n",
    "print(\">> Final flagged channels:\", bad_channels)\n",
    "\n",
    "# Summarize in a DataFrame \n",
    "df = pd.DataFrame({\n",
    "    \"Channel\":     [bad_chan_identifier.ch_names[p]      for p in picks],\n",
    "    \"PSD_Z\":       np.round(psd_z,    2),\n",
    "    \"P2P_Z\":       np.round(p2p_z,    2),\n",
    "    \"Corr_Z\":      np.round(corr_z,   2),\n",
    "    \"Var_Z\":       np.round(var_z,    2),\n",
    "    \"Max_Freq_Z\":  np.round(max_freq_z,2),\n",
    "    \"Flagged\":     mask_all\n",
    "})\n",
    "print(df)\n",
    "\n",
    "# Visual check: all individual PSDs\n",
    "bad_chan_identifier.plot_psd(\n",
    "    fmin=1.0, fmax=80.0,\n",
    "    picks=picks,\n",
    "    dB=True,\n",
    "    average=False,\n",
    "    show=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f907750a",
   "metadata": {},
   "source": [
    "#### Plot PSD of individual channels flagged above and decide whether to remove or keep them in\n",
    "For example, if Fp2 and Fp1 are flagged, this is likely eyeblinks (high power in low frequencies), so do not remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41503046",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "# picks can be either indices or names\n",
    "picks = mne.pick_channels(bad_chan_identifier.ch_names, include=bad_channels)\n",
    "\n",
    "# compute PSD of bad channels\n",
    "bad_chan_identifier.plot_psd(\n",
    "    fmin=1.0,\n",
    "    fmax=80.0,\n",
    "    picks=picks,\n",
    "    dB=True,\n",
    "    average=False,\n",
    ")\n",
    "\n",
    "for ch in bad_channels:\n",
    "    # one figure per channel\n",
    "    fig = bad_chan_identifier.plot_psd(\n",
    "        fmin=1.0,\n",
    "        fmax=80.0,\n",
    "        picks=[ch],\n",
    "        dB=True,\n",
    "        average=False,\n",
    "        show=False   \n",
    "    )\n",
    "    fig.suptitle(f'PSD for {ch}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fad809e",
   "metadata": {},
   "source": [
    "#### Plot channel traces for visual inspection and select bad ones guided by metrics above and visual check here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f40f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# Plot raw signal\n",
    "bad_chan_identifier.plot(n_channels = len(ch_names), scalings=\"auto\", block=True) # Cell block waits for plot to be closed before continuing (i.e., saving)\n",
    "\n",
    "file_p = join(save_path, f\"{sub.replace(' ', '_')}_art_and_chan_removed_eeg.fif\")\n",
    "bad_chan_identifier.save(file_p, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a6457f",
   "metadata": {},
   "source": [
    "#### After identifying noisy channels and bad segments, re-reference to average\n",
    "It's important at this step that only channels that are EEG channels, have the EEG label! (see first step of script (after loading data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f12381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure bad channels are listed here, otherwise they will be included in the average reference\n",
    "bad_chan_identifier.info['bads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0743bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_ref_data = []\n",
    "av_ref_data = bad_chan_identifier.copy().set_eeg_reference(ref_channels=\"average\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5211b1db",
   "metadata": {},
   "source": [
    "#### Plot PSD again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc1875",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "### Plot PSD of signal (averaging all channels)\n",
    "psd_final_avg = av_ref_data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=1, fmax=130, window=\"hamming\")\n",
    "psd_final_avg.plot(dB=True, average=True).suptitle(f\"{sub} PSD after re-referencing\")\n",
    "plt.show()\n",
    "\n",
    "### Plot PSD of signal (not averaging)\n",
    "psd_final = av_ref_data.compute_psd(method=\"welch\", picks=\"eeg\", fmin=1, fmax=130, window=\"hamming\")\n",
    "psd_final.plot(dB=True, average=False).suptitle(f\"{sub} PSD after re-referencing\")\n",
    "plt.savefig(join(sub_save_path, f\"{sub}_after_reRef.png\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ceed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "av_ref_data.plot(n_channels = len(ch_names), scalings=\"auto\", title=\"After re-referencing to average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab0b03e",
   "metadata": {},
   "source": [
    "### Independent Component Analysis\n",
    "If ICA has already been fitted for this subject, it will be loaded.\n",
    "If ICA hasn't been fitted, it will be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a93d52",
   "metadata": {},
   "source": [
    "Random note: when cognitive load increases, blinking usually decreases. Because when participants are expecting something important to happen (stimulus appearance), they will unconsciously try not to blink, to pay more attention (source: https://www.youtube.com/watch?v=AXCxrDikpaM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4d405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the fitted or loaded ICA objects\n",
    "ica_fit_dict = {}\n",
    " \n",
    "# Construct the file path for the ICA file\n",
    "ica_file_path = join(saving_path, 'sub_data', f\"{sub}\", f\"{sub}-ica.fif\")\n",
    "    \n",
    "# Check if the ICA file exists\n",
    "if os.path.exists(ica_file_path):\n",
    "    # If it exists, load the ICA object\n",
    "    ica = read_ica(ica_file_path)\n",
    "    print(f\"Loaded ICA for {sub} from {ica_file_path}\")\n",
    "\n",
    "else:\n",
    "    # If it doesn't exist, fit ICA to the data\n",
    "    ica = ICA(n_components=None, random_state=11, method='infomax') # Number of components is chosen by function to account for 99%\n",
    "    ica.fit(av_ref_data.copy().pick_types(eeg=True, eog=True, ecg=True))                                  \n",
    "   \n",
    "    # Save the ICA object to file (saving the ICA decomposition, not any raw/cleaned data)\n",
    "    ica.save(ica_file_path)\n",
    "    print(f\"Fitted and saved ICA for {sub} at {ica_file_path}\")\n",
    "    \n",
    "ica_fit_dict = ica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8fadb1",
   "metadata": {},
   "source": [
    "#### Components identified\n",
    "By clicking on the components you will get more info about them (only in interactive mode (qt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e632843",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "fig = ica.plot_components(inst=av_ref_data,  psd_args={'fmin': 0, 'fmax': 80}, ncols=6, nrows=6) #Topographies of each component\n",
    "plt.savefig(join(sub_save_path, f\"{sub}_ica_components.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d2ef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ica.n_components_):\n",
    "    fig = ica_fit_dict.plot_properties(picks=[i], inst=av_ref_data, show=False) #Topographies of each component\n",
    "    plt.savefig(join(sub_save_path, f\"{sub}_ica_component_{i}.png\"), dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1f614",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig_sources = ica.plot_sources(av_ref_data) # Timeseries of each ICA component\n",
    "plt.savefig(join(sub_save_path, f\"{sub}_ica_sources.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa635f2",
   "metadata": {},
   "source": [
    "### Exclude components + apply ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_exclude = [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] # saving this in variable for easier input below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec759a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.exclude = to_exclude # exclude components manually by adding component number here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3af4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply ICA to the data\n",
    "data_after_ica = ica.apply(av_ref_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8883cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica # here we can check that the correct components have been excluded, gives us ica info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265a64b",
   "metadata": {},
   "source": [
    "#### Visual inspection after ICA :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feda663",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_after_ica.plot(n_channels=len(ch_names), scalings=\"auto\", title=\"After ICA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd4b855",
   "metadata": {},
   "source": [
    "### If necessary, interpolate bad channels after ICA ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdcf82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data_interp = data_after_ica.copy().interpolate_bads(reset_bads=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9926af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data_interp.plot(n_channels=len(ch_names), scalings=\"auto\", title=\"After ICA and interpolation of bad channels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5fe5ca",
   "metadata": {},
   "source": [
    "#### Save file after ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f973b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(saving_path, \"sub_data\", f\"{sub}\", \"data\")\n",
    "os.makedirs(save_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "file_p = join(save_path, f\"{sub.replace(' ', '_')}_postICA_EEGdata_eeg.fif\")\n",
    "data_after_ica = eeg_data_interp.copy()\n",
    "data_after_ica.save(file_p, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25de04a",
   "metadata": {},
   "source": [
    "### Plot PSD after ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1345178",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "### Plot PSD of signal (not averaging)\n",
    "psd_after_ica = data_after_ica.compute_psd(method=\"welch\", picks=\"eeg\", fmin=1, fmax=80, window=\"hamming\")\n",
    "psd_after_ica.plot(dB=True, average=False).suptitle(f\"{sub} PSD after ICA\")\n",
    "sub_save_path = join(saving_path, \"sub_data\", f\"{sub}\", \"figures\", \"PSDs\")\n",
    "plt.savefig(join(sub_save_path, f\"{sub}_after_ICA_PSD.png\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda58920",
   "metadata": {},
   "source": [
    "## Extract epochs to check data quality after ICA and plot specific channels: \n",
    "the C3/C4 channels are the ones above the motor cortex, they can be plotted to check that the expected beta desynchronization is visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80588fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "events, event_dict = mne.events_from_annotations(data_after_ica)\n",
    "# List of keys to keep\n",
    "keys_to_keep = ['GC', 'GF', 'GO', 'GS', 'continue', 'stop']\n",
    "\n",
    "# Create the new dictionary by filtering the original one\n",
    "filtered_event_dict = {key: event_dict[key] for key in keys_to_keep}\n",
    "\n",
    "print(filtered_event_dict)\n",
    "# Get the event codes (values) from the filtered dictionary\n",
    "valid_event_codes = list(filtered_event_dict.values())\n",
    "\n",
    "# Filter the events array where the event code is in the valid_event_codes list\n",
    "filtered_events = np.array([event for event in events if event[2] in valid_event_codes])\n",
    "\n",
    "print(filtered_events)\n",
    "#picks = [raw.ch_names[0], raw.ch_names[1]]\n",
    "tmin = -0.5\n",
    "tmax = 1.5\n",
    "epochs = mne.Epochs(data_after_ica, filtered_events, event_id=filtered_event_dict, tmin=tmin, tmax=tmax, baseline=(None, 0), preload=True)\n",
    "metadata = pd.DataFrame({'subject':[sub] * len(epochs)})\n",
    "epochs.metadata = metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f0d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs['GO'].average().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57bda4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of evoked objects from conditions names\n",
    "evokeds = [epochs[name].average() for name in (\"GO\", \"GF\",\"GC\", \"GS\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e919a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "colors = \"blue\", \"red\", \"green\", \"black\"\n",
    "title = \"Evoked responses\"\n",
    "\n",
    "fig, axes = plt.subplots(1)\n",
    "\n",
    "mne.viz.plot_evoked_topo(evokeds, title=title, background_color=\"w\", axes=axes)\n",
    "\n",
    "fig.savefig(join(saving_path, 'evoked_responses.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5260f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = io.load_behav_data([session_id], onedrive_path)\n",
    "\n",
    "stats = {}\n",
    "stats = utils.extract_stats(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553de7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare variables and dictionaries for storing results\n",
    "# Dictionary to store subject epochs in\n",
    "sub_dict_epochs_subsets = {}  #  Stores the epochs for each condition and for each subject/session\n",
    "sub_dict_lm_GO = {}  #  Stores the epochs for lm_GO trials for each subject/session\n",
    "sub_dict_RT = {}  #  Stores the mean reaction time for each trial type\n",
    "sub_dict_stats = {}  #  Stores behavioral stats for each subject/session\n",
    "\n",
    "cluster_results_dict = {}\n",
    "cluster_results_dict = defaultdict(dict)  # Each missing key gets an empty dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7699a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_dict = {}\n",
    "sub = session_id[:6]\n",
    "subject_ID = session_id.split(' ') [0]\n",
    "condition = session_id.split(' ') [1] + ' ' + session_id.split(' ') [2]\n",
    "sub_onedrive_path = join(onedrive_path, subject_ID)\n",
    "sub_onedrive_path_task = join(onedrive_path, subject_ID, 'synced_data', session_id)\n",
    "\n",
    "saving_path_single = join(results_path, 'single_sub', f'{sub} mSST','eeg') \n",
    "os.makedirs(saving_path_single, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "epochs, filtered_event_dict = preprocessing.create_epochs(data_after_ica, session_id)\n",
    "\n",
    "mSST_raw_behav_session_data_path = join(\n",
    "        onedrive_path, subject_ID, \"raw_data\", 'BEHAVIOR', condition, 'mSST'\n",
    "        )\n",
    "for filename in os.listdir(mSST_raw_behav_session_data_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            fname = filename\n",
    "filepath_behav = join(mSST_raw_behav_session_data_path, fname)\n",
    "df = pd.read_csv(filepath_behav)\n",
    "\n",
    "# return the index of the first row which is not filled by a Nan value:\n",
    "start_task_index = df['blocks.thisRepN'].first_valid_index()\n",
    "# Crop dataframe in 2 parts: before and after the task:\n",
    "df_maintask = df.iloc[start_task_index:-1]\n",
    "\n",
    "# remove the trials with early presses, as in these trials the cues were not presented\n",
    "early_presses = df_maintask[df_maintask['early_press_resp.corr'] == 1]\n",
    "early_presses_trials = list(early_presses.index)\n",
    "number_early_presses = len(early_presses_trials)\n",
    "\n",
    "# remove trials with early presses from the dataframe:\n",
    "df_maintask_copy = df_maintask.drop(early_presses_trials)\n",
    "\n",
    "# Filter successful and unsuccessful trials:\n",
    "(epochs_subsets, epochs_lm, mean_RT_dict) = preprocessing.create_epochs_subsets_from_behav(\n",
    "        df_maintask_copy, \n",
    "        epochs, \n",
    "        filtered_event_dict\n",
    "        )\n",
    "\n",
    "sub_dict_epochs_subsets[session_id] = epochs_subsets\n",
    "sub_dict_lm_GO[session_id] = epochs_lm\n",
    "sub_dict_RT[session_id] = mean_RT_dict\n",
    "sub_dict_stats[session_id] = stats[session_id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecba114",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "### TFR PARAMETERS ###\n",
    "######################\n",
    "\n",
    "decim = 1 \n",
    "freqs = np.arange(1, 40, 1) \n",
    "# For 500ms time resolution at 1 Hz: n_cycles = 1 * 0.5 = 0.5\n",
    "# For 50ms time resolution at 40 Hz: n_cycles = 40 * 0.05 = 2\n",
    "# Linear interpolation between these points\n",
    "#n_cycles = 0.5 + (freqs - 1) * (2 - 0.5) / (40 - 1)\n",
    "#n_cycles = freqs / 2.0\n",
    "n_cycles = np.minimum(np.maximum(freqs / 2.0, 2), 10)\n",
    "\n",
    "tfr_args = dict(\n",
    "    method=\"morlet\",\n",
    "    freqs=freqs,\n",
    "    n_cycles=n_cycles,\n",
    "    decim=decim,\n",
    "    return_itc=False,\n",
    "    average=False\n",
    ")        \n",
    "\n",
    "tmin_tmax = [-500, 1500]\n",
    "vmin_vmax = [-70, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd8fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sub_dict_subsets = {key: value for key, value in sub_dict_epochs_subsets.items() if sub in key}\n",
    "print(single_sub_dict_subsets.keys())\n",
    "single_sub_dict_lm_GO = {key: value for key, value in sub_dict_lm_GO.items() if sub in key}\n",
    "single_sub_RT_dict = {key: value for key, value in sub_dict_RT.items() if sub in key}\n",
    "single_sub_stats_dict = {key: value for key, value in sub_dict_stats.items() if sub in key}\n",
    "saving_path_single = join(results_path, 'single_sub', f'{sub} mSST','lfp_perc_sig_change', 'beta_only')\n",
    "os.makedirs(saving_path_single, exist_ok=True)  # Create the directory if it doesn't exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ca5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "epoch_cond = 'GO_successful'\n",
    "t_min_max = [-500, 1500]\n",
    "data = epochs_subsets[epoch_cond]\n",
    "C4_epochs = data.copy().pick([\"C3\"])\n",
    "power_c4 = C4_epochs.compute_tfr(**tfr_args)\n",
    "mean_power_c4 = np.nanmean(power_c4.data, axis=0).squeeze()\n",
    "\n",
    "times = power_c4.times * 1000  # Convert to milliseconds\n",
    "freqs = power_c4.freqs\n",
    "\n",
    "baseline_indices = (times >= -500) & (times <= -200)\n",
    "baseline_power_c4 = np.nanmean(mean_power_c4[:, baseline_indices], axis=1, keepdims=True)\n",
    "percentage_change_c4 = (mean_power_c4 - baseline_power_c4) / baseline_power_c4 * 100\n",
    "\n",
    "time_indices = np.logical_and(times >= t_min_max[0], times <= t_min_max[1])\n",
    "sliced_data = percentage_change_c4[:, time_indices].squeeze()    \n",
    "\n",
    "plt.imshow(sliced_data, aspect='auto', origin='lower', \n",
    "        extent=[t_min_max[0], t_min_max[1], \n",
    "        tfr_args[\"freqs\"][0], tfr_args[\"freqs\"][-1]], \n",
    "        cmap='jet', vmin=vmin_vmax[0], vmax=vmin_vmax[-1]\n",
    ")\n",
    "plt.axvline(x=0, color='k', linestyle='--', linewidth=1)\n",
    "plt.title(f\"Percentage Change in Power for {epoch_cond} - C3\")\n",
    "plt.xlabel(\"Time from GO cue (ms)\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.colorbar(label=\"Percentage Change (%)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908e3930",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_cond = 'GF_successful'\n",
    "t_min_max = [-500, 1500]\n",
    "data = epochs_subsets[epoch_cond]\n",
    "C4_epochs = data.copy().pick([\"C3\"])\n",
    "power_c4 = C4_epochs.compute_tfr(**tfr_args)\n",
    "mean_power_c4 = np.nanmean(power_c4.data, axis=0).squeeze()\n",
    "\n",
    "times = power_c4.times * 1000  # Convert to milliseconds\n",
    "freqs = power_c4.freqs\n",
    "\n",
    "baseline_indices = (times >= -500) & (times <= -200)\n",
    "baseline_power_c4 = np.nanmean(mean_power_c4[:, baseline_indices], axis=1, keepdims=True)\n",
    "percentage_change_c4 = (mean_power_c4 - baseline_power_c4) / baseline_power_c4 * 100\n",
    "\n",
    "time_indices = np.logical_and(times >= t_min_max[0], times <= t_min_max[1])\n",
    "sliced_data = percentage_change_c4[:, time_indices].squeeze()    \n",
    "\n",
    "plt.imshow(sliced_data, aspect='auto', origin='lower', \n",
    "        extent=[t_min_max[0], t_min_max[1], \n",
    "        tfr_args[\"freqs\"][0], tfr_args[\"freqs\"][-1]], \n",
    "        cmap='jet', vmin=vmin_vmax[0], vmax=vmin_vmax[-1]\n",
    ")\n",
    "plt.axvline(x=0, color='k', linestyle='--', linewidth=1)\n",
    "plt.title(f\"Percentage Change in Power for {epoch_cond} - C3\")\n",
    "plt.xlabel(\"Time from GO cue (ms)\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.colorbar(label=\"Percentage Change (%)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bbf88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_cond = 'GS_successful'\n",
    "t_min_max = [-500, 1500]\n",
    "data = epochs_subsets[epoch_cond]\n",
    "fz_epochs = data.copy().pick([\"Fz\"])\n",
    "power_fz = fz_epochs.compute_tfr(**tfr_args)\n",
    "mean_power_fz = np.nanmean(power_fz.data, axis=0).squeeze()\n",
    "\n",
    "times = power_fz.times * 1000  # Convert to milliseconds\n",
    "freqs = power_fz.freqs\n",
    "\n",
    "baseline_indices = (times >= -500) & (times <= -200)\n",
    "baseline_power_fz = np.nanmean(mean_power_fz[:, baseline_indices], axis=1, keepdims=True)\n",
    "percentage_change_fz = (mean_power_fz - baseline_power_fz) / baseline_power_fz * 100\n",
    "\n",
    "time_indices = np.logical_and(times >= t_min_max[0], times <= t_min_max[1])\n",
    "sliced_data_fz = percentage_change_fz[:, time_indices].squeeze()    \n",
    "\n",
    "plt.imshow(sliced_data_fz, aspect='auto', origin='lower', \n",
    "        extent=[t_min_max[0], t_min_max[1], \n",
    "        tfr_args[\"freqs\"][0], tfr_args[\"freqs\"][-1]], \n",
    "        cmap='jet', vmin=vmin_vmax[0], vmax=vmin_vmax[-1]\n",
    ")\n",
    "plt.axvline(x=0, color='k', linestyle='--', linewidth=1)\n",
    "plt.title(f\"Percentage Change in Power for {epoch_cond} - Fz\")\n",
    "plt.xlabel(\"Time from GO cue (ms)\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.colorbar(label=\"Percentage Change (%)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23b9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_cond = 'GS_unsuccessful'\n",
    "t_min_max = [-500, 1500]\n",
    "data = epochs_subsets[epoch_cond]\n",
    "fz_epochs = data.copy().pick([\"Fz\"])\n",
    "power_fz = fz_epochs.compute_tfr(**tfr_args)\n",
    "mean_power_fz = np.nanmean(power_fz.data, axis=0).squeeze()\n",
    "\n",
    "times = power_fz.times * 1000  # Convert to milliseconds\n",
    "freqs = power_fz.freqs\n",
    "\n",
    "baseline_indices = (times >= -500) & (times <= -200)\n",
    "baseline_power_fz = np.nanmean(mean_power_fz[:, baseline_indices], axis=1, keepdims=True)\n",
    "percentage_change_fz = (mean_power_fz - baseline_power_fz) / baseline_power_fz * 100\n",
    "\n",
    "time_indices = np.logical_and(times >= t_min_max[0], times <= t_min_max[1])\n",
    "sliced_data_fz = percentage_change_fz[:, time_indices].squeeze()    \n",
    "\n",
    "plt.imshow(sliced_data_fz, aspect='auto', origin='lower', \n",
    "        extent=[t_min_max[0], t_min_max[1], \n",
    "        tfr_args[\"freqs\"][0], tfr_args[\"freqs\"][-1]], \n",
    "        cmap='jet', vmin=vmin_vmax[0], vmax=vmin_vmax[-1]\n",
    ")\n",
    "plt.axvline(x=0, color='k', linestyle='--', linewidth=1)\n",
    "plt.title(f\"Percentage Change in Power for {epoch_cond} - Fz\")\n",
    "plt.xlabel(\"Time from GO cue (ms)\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.colorbar(label=\"Percentage Change (%)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24540ad1",
   "metadata": {},
   "source": [
    "#### NOTE: Here I have kept ALL epochs, even if they have previously been marked as bad (e.g.,movement), and I will have to remove these again now. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ab604b",
   "metadata": {},
   "source": [
    "### Note\n",
    "Once each subject has been preprocessed and epochs cleaned, other scripts will load the cleaned epochs and run the analyses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ephy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
